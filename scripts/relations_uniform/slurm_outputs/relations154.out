2024-05-10 02:39:45 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 154 ---------------
2024-05-10 02:39:45 INFO     Contexts were splited into 716 paragraphs, which are 2.402684563758389 paragraphs on average per one report. The overall paragraph average length (characters) is 2310.9930167597763
2024-05-10 02:39:45 INFO     Contexts were splited into 79 paragraphs, which are 1.880952380952381 paragraphs on average per one report. The overall paragraph average length (characters) is 2278.4430379746836
2024-05-10 02:39:46 INFO     Contexts were splited into 188 paragraphs, which are 2.186046511627907 paragraphs on average per one report. The overall paragraph average length (characters) is 2243.494680851064
2024-05-10 02:40:13 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-10 02:46:34 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 04:15:29 INFO     the model is trained
2024-05-10 04:36:52 INFO     evaluation data are prepared
2024-05-10 08:35:50 INFO     QA scores: {'exact_match': 92.48952362602958, 'f1': 97.48979927998644}
2024-05-10 08:35:50 INFO     PR scores: {'p@1': 0.988927556476085, 'p@2': 0.9983623139540485, 'p@3': 0.9998615191946438}
2024-05-10 08:36:00 INFO     PRQA scores: {'exact_match': 91.6116757381629, 'f1': 96.72857464050423}
{'loss': 0.6372, 'grad_norm': 6.461517333984375, 'learning_rate': 2.866202836499866e-05, 'epoch': 0.0445990545000446}
{'loss': 0.2388, 'grad_norm': 8.360316276550293, 'learning_rate': 2.7324056729997325e-05, 'epoch': 0.0891981090000892}
{'loss': 0.1968, 'grad_norm': 7.515718460083008, 'learning_rate': 2.5986085094995986e-05, 'epoch': 0.1337971635001338}
{'loss': 0.1596, 'grad_norm': 0.021349934861063957, 'learning_rate': 2.464811345999465e-05, 'epoch': 0.1783962180001784}
{'loss': 0.1434, 'grad_norm': 11.408392906188965, 'learning_rate': 2.331014182499331e-05, 'epoch': 0.222995272500223}
{'loss': 0.1318, 'grad_norm': 0.8776344656944275, 'learning_rate': 2.197217018999197e-05, 'epoch': 0.2675943270002676}
{'loss': 0.1432, 'grad_norm': 2.490236520767212, 'learning_rate': 2.0634198554990635e-05, 'epoch': 0.3121933815003122}
{'loss': 0.1224, 'grad_norm': 0.4684092402458191, 'learning_rate': 1.9296226919989295e-05, 'epoch': 0.3567924360003568}
{'loss': 0.0999, 'grad_norm': 2.452178478240967, 'learning_rate': 1.795825528498796e-05, 'epoch': 0.4013914905004014}
{'loss': 0.1185, 'grad_norm': 2.0349509716033936, 'learning_rate': 1.662028364998662e-05, 'epoch': 0.445990545000446}
{'loss': 0.0906, 'grad_norm': 28.782222747802734, 'learning_rate': 1.528231201498528e-05, 'epoch': 0.4905895995004906}
{'loss': 0.0992, 'grad_norm': 6.3940019607543945, 'learning_rate': 1.3944340379983944e-05, 'epoch': 0.5351886540005352}
{'loss': 0.0775, 'grad_norm': 0.7805275321006775, 'learning_rate': 1.2606368744982607e-05, 'epoch': 0.5797877085005798}
{'loss': 0.0751, 'grad_norm': 8.311152458190918, 'learning_rate': 1.1268397109981269e-05, 'epoch': 0.6243867630006243}
{'loss': 0.0853, 'grad_norm': 0.10594108700752258, 'learning_rate': 9.930425474979931e-06, 'epoch': 0.668985817500669}
{'loss': 0.0743, 'grad_norm': 2.6041219234466553, 'learning_rate': 8.592453839978594e-06, 'epoch': 0.7135848720007136}
{'loss': 0.0592, 'grad_norm': 1.6436328887939453, 'learning_rate': 7.254482204977254e-06, 'epoch': 0.7581839265007582}
{'loss': 0.068, 'grad_norm': 13.079662322998047, 'learning_rate': 5.916510569975916e-06, 'epoch': 0.8027829810008028}
{'loss': 0.0545, 'grad_norm': 0.023418303579092026, 'learning_rate': 4.5785389349745795e-06, 'epoch': 0.8473820355008473}
{'loss': 0.0506, 'grad_norm': 5.213771343231201, 'learning_rate': 3.2405672999732404e-06, 'epoch': 0.891981090000892}
{'loss': 0.0572, 'grad_norm': 0.12502393126487732, 'learning_rate': 1.902595664971903e-06, 'epoch': 0.9365801445009366}
{'loss': 0.054, 'grad_norm': 0.03945019841194153, 'learning_rate': 5.646240299705646e-07, 'epoch': 0.9811791990009812}
{'eval_loss': 0.27360859513282776, 'eval_runtime': 2307.2819, 'eval_samples_per_second': 178.483, 'eval_steps_per_second': 0.697, 'epoch': 1.0}
{'train_runtime': 5333.7895, 'train_samples_per_second': 33.629, 'train_steps_per_second': 2.102, 'train_loss': 0.12760984073537177, 'epoch': 1.0}
Post-processing 524311 example predictions split into 1379527 features.
{
    "154": {
        "QA": {
            "exact_match": 92.48952362602958,
            "f1": 97.48979927998644
        },
        "PR": {
            "p@1": 0.988927556476085,
            "p@2": 0.9983623139540485,
            "p@3": 0.9998615191946438
        },
        "PRQA": {
            "exact_match": 91.6116757381629,
            "f1": 96.72857464050423
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 492057 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 492057 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
