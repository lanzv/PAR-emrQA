2024-05-07 12:55:26 INFO     ------------- Experiment: model BERTbase, frequency threshold 100 ---------------
2024-05-07 12:55:26 INFO     Contexts were splited into 4977 sentence groups, which are 27.19672131147541 groups on average per one report
2024-05-07 12:55:27 INFO     Contexts were splited into 790 paragraphs, which are 4.316939890710382 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 100. The overall paragraph average length (characters) is 1545.6050632911392
2024-05-07 12:55:27 INFO     Contexts were splited into 818 sentence groups, which are 31.46153846153846 groups on average per one report
2024-05-07 12:55:28 INFO     Contexts were splited into 74 paragraphs, which are 2.8461538461538463 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 100. The overall paragraph average length (characters) is 2476.445945945946
2024-05-07 12:55:28 INFO     Contexts were splited into 1362 sentence groups, which are 25.69811320754717 groups on average per one report
2024-05-07 12:55:29 WARNING  The evidenc 'CEFPODOXIME PROXETIL 200 MG PO BID X 16 doses
Food/Drug Interaction Instruction Give with meals
' is in wrong format and it does not occure in the paragraph 'POTENTIALLY SERIOUS INTERACTION: WARFARIN &amp; SIMVASTATIN
Reason for override: already tolerated , home medication ,
aware
CEFPODOXIME PROXETIL 200 MG PO BID X 16 doses
Starting Today ( 6/25 ) HOLD IF: rash
Food/Drug Interaction Instruction Give with meals
Alert overridden: Override added on 11/4/05 by :
on order for CEFPODOXIME PROXETIL PO ( ref # 703442345 )
Pt. has a POSSIBLE allergy to Penicillins; reaction is
RASH. Reason for override: cannot tolerate floroquinolones
and needs gram neg coverage. has
tolerated cefalosporins well in the past.
'
2024-05-07 12:55:29 INFO     Contexts were splited into 224 paragraphs, which are 4.226415094339623 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 100. The overall paragraph average length (characters) is 1534.861607142857
2024-05-07 12:55:37 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 12:59:39 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 14:23:25 INFO     the model is trained
2024-05-07 14:29:22 INFO     evaluation data are prepared
2024-05-07 15:53:07 INFO     QA scores: {'exact_match': 29.86985095141961, 'f1': 70.65396735011916}
2024-05-07 15:53:07 INFO     PR scores: {'p@1': 0.9522572054465014, 'p@2': 0.9922898500923499, 'p@3': 0.9959838494910013}
2024-05-07 15:53:10 INFO     PRQA scores: {'exact_match': 28.828229027962717, 'f1': 68.84258894359607}
{'loss': 1.1621, 'grad_norm': 4.375336647033691, 'learning_rate': 2.898408398239079e-05, 'epoch': 0.033863867253640365}
{'loss': 0.777, 'grad_norm': 3.08536696434021, 'learning_rate': 2.7968167964781576e-05, 'epoch': 0.06772773450728073}
{'loss': 0.6989, 'grad_norm': 10.066577911376953, 'learning_rate': 2.695225194717237e-05, 'epoch': 0.1015916017609211}
{'loss': 0.62, 'grad_norm': 10.948795318603516, 'learning_rate': 2.5936335929563155e-05, 'epoch': 0.13545546901456146}
{'loss': 0.5929, 'grad_norm': 6.489750862121582, 'learning_rate': 2.4920419911953945e-05, 'epoch': 0.16931933626820184}
{'loss': 0.5209, 'grad_norm': 11.150599479675293, 'learning_rate': 2.3904503894344734e-05, 'epoch': 0.2031832035218422}
{'loss': 0.4827, 'grad_norm': 5.0098347663879395, 'learning_rate': 2.2888587876735524e-05, 'epoch': 0.23704707077548257}
{'loss': 0.4545, 'grad_norm': 5.541595935821533, 'learning_rate': 2.1872671859126313e-05, 'epoch': 0.2709109380291229}
{'loss': 0.4222, 'grad_norm': 5.702852249145508, 'learning_rate': 2.0856755841517103e-05, 'epoch': 0.3047748052827633}
{'loss': 0.4137, 'grad_norm': 9.467568397521973, 'learning_rate': 1.984083982390789e-05, 'epoch': 0.3386386725364037}
{'loss': 0.3959, 'grad_norm': 4.9364705085754395, 'learning_rate': 1.8824923806298682e-05, 'epoch': 0.372502539790044}
{'loss': 0.3786, 'grad_norm': 20.46636390686035, 'learning_rate': 1.7809007788689468e-05, 'epoch': 0.4063664070436844}
{'loss': 0.3443, 'grad_norm': 12.870050430297852, 'learning_rate': 1.6793091771080257e-05, 'epoch': 0.44023027429732475}
{'loss': 0.3168, 'grad_norm': 5.870997428894043, 'learning_rate': 1.5777175753471047e-05, 'epoch': 0.47409414155096513}
{'loss': 0.3007, 'grad_norm': 8.070658683776855, 'learning_rate': 1.4761259735861835e-05, 'epoch': 0.5079580088046055}
{'loss': 0.2846, 'grad_norm': 24.103750228881836, 'learning_rate': 1.3745343718252626e-05, 'epoch': 0.5418218760582458}
{'loss': 0.276, 'grad_norm': 7.012876987457275, 'learning_rate': 1.2729427700643414e-05, 'epoch': 0.5756857433118863}
{'loss': 0.2571, 'grad_norm': 18.056795120239258, 'learning_rate': 1.1713511683034203e-05, 'epoch': 0.6095496105655266}
{'loss': 0.2598, 'grad_norm': 1.4719244241714478, 'learning_rate': 1.0697595665424991e-05, 'epoch': 0.6434134778191669}
{'loss': 0.2375, 'grad_norm': 20.214468002319336, 'learning_rate': 9.681679647815782e-06, 'epoch': 0.6772773450728073}
{'loss': 0.2194, 'grad_norm': 11.545589447021484, 'learning_rate': 8.66576363020657e-06, 'epoch': 0.7111412123264477}
{'loss': 0.2193, 'grad_norm': 10.302393913269043, 'learning_rate': 7.64984761259736e-06, 'epoch': 0.745005079580088}
{'loss': 0.205, 'grad_norm': 1.847826600074768, 'learning_rate': 6.633931594988148e-06, 'epoch': 0.7788689468337284}
{'loss': 0.1923, 'grad_norm': 5.090452671051025, 'learning_rate': 5.618015577378937e-06, 'epoch': 0.8127328140873687}
{'loss': 0.1772, 'grad_norm': 15.946146965026855, 'learning_rate': 4.602099559769725e-06, 'epoch': 0.8465966813410092}
{'loss': 0.1851, 'grad_norm': 14.918684959411621, 'learning_rate': 3.5861835421605147e-06, 'epoch': 0.8804605485946495}
{'loss': 0.1765, 'grad_norm': 0.8026226758956909, 'learning_rate': 2.570267524551304e-06, 'epoch': 0.9143244158482898}
{'loss': 0.1674, 'grad_norm': 18.31331443786621, 'learning_rate': 1.5543515069420929e-06, 'epoch': 0.9481882831019303}
{'loss': 0.1685, 'grad_norm': 6.926032543182373, 'learning_rate': 5.384354893328818e-07, 'epoch': 0.9820521503555706}
{'eval_loss': 0.7955026030540466, 'eval_runtime': 1038.4232, 'eval_samples_per_second': 179.311, 'eval_steps_per_second': 0.701, 'epoch': 1.0}
{'train_runtime': 5025.2262, 'train_samples_per_second': 47.008, 'train_steps_per_second': 2.938, 'train_loss': 0.37218277437421293, 'epoch': 1.0}
Post-processing 205344 example predictions split into 500729 features.
{
    "100": {
        "QA": {
            "exact_match": 29.86985095141961,
            "f1": 70.65396735011916
        },
        "PR": {
            "p@1": 0.9522572054465014,
            "p@2": 0.9922898500923499,
            "p@3": 0.9959838494910013
        },
        "PRQA": {
            "exact_match": 28.828229027962717,
            "f1": 68.84258894359607
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3652010 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3652010 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
