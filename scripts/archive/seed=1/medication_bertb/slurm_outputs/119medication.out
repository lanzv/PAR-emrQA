2024-05-09 18:02:33 INFO     ------------- Experiment: model BERTbase, frequency threshold 119 ---------------
2024-05-09 18:02:34 INFO     Contexts were splited into 4977 sentence groups, which are 27.19672131147541 groups on average per one report
2024-05-09 18:02:35 INFO     Contexts were splited into 672 paragraphs, which are 3.6721311475409837 paragraphs on average per one report. There are 3 unique topics with frequency threshold (greater or equal) 119. The overall paragraph average length (characters) is 1817.0059523809523
2024-05-09 18:02:35 INFO     Contexts were splited into 818 sentence groups, which are 31.46153846153846 groups on average per one report
2024-05-09 18:02:35 INFO     Contexts were splited into 58 paragraphs, which are 2.230769230769231 paragraphs on average per one report. There are 3 unique topics with frequency threshold (greater or equal) 119. The overall paragraph average length (characters) is 3159.603448275862
2024-05-09 18:02:35 INFO     Contexts were splited into 1362 sentence groups, which are 25.69811320754717 groups on average per one report
2024-05-09 18:02:37 WARNING  The evidenc 'CEFPODOXIME PROXETIL 200 MG PO BID X 16 doses
Food/Drug Interaction Instruction Give with meals
' is in wrong format and it does not occure in the paragraph 'POTENTIALLY SERIOUS INTERACTION: WARFARIN &amp; SIMVASTATIN
Reason for override: already tolerated , home medication ,
aware
CEFPODOXIME PROXETIL 200 MG PO BID X 16 doses
Starting Today ( 6/25 ) HOLD IF: rash
Food/Drug Interaction Instruction Give with meals
Alert overridden: Override added on 11/4/05 by :
on order for CEFPODOXIME PROXETIL PO ( ref # 703442345 )
Pt. has a POSSIBLE allergy to Penicillins; reaction is
RASH. Reason for override: cannot tolerate floroquinolones
and needs gram neg coverage. has
tolerated cefalosporins well in the past.
'
2024-05-09 18:02:37 INFO     Contexts were splited into 184 paragraphs, which are 3.4716981132075473 paragraphs on average per one report. There are 3 unique topics with frequency threshold (greater or equal) 119. The overall paragraph average length (characters) is 1868.5271739130435
2024-05-09 18:02:45 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-09 18:07:26 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-09 19:33:27 INFO     the model is trained
2024-05-09 19:39:24 INFO     evaluation data are prepared
2024-05-09 20:59:27 INFO     QA scores: {'exact_match': 28.787423220652034, 'f1': 69.92206278398578}
2024-05-09 20:59:27 INFO     PR scores: {'p@1': 0.9583136463210343, 'p@2': 0.9928267686095958, 'p@3': 0.996649628452386}
2024-05-09 20:59:30 INFO     PRQA scores: {'exact_match': 27.692109445470557, 'f1': 68.2645174327155}
{'loss': 1.1408, 'grad_norm': 12.575592041015625, 'learning_rate': 2.9015037100269223e-05, 'epoch': 0.03283209665769256}
{'loss': 0.8077, 'grad_norm': 11.348939895629883, 'learning_rate': 2.803007420053845e-05, 'epoch': 0.06566419331538512}
{'loss': 0.6883, 'grad_norm': 2.9347445964813232, 'learning_rate': 2.704511130080767e-05, 'epoch': 0.09849628997307767}
{'loss': 0.6527, 'grad_norm': 2.624504327774048, 'learning_rate': 2.6060148401076893e-05, 'epoch': 0.13132838663077023}
{'loss': 0.5452, 'grad_norm': 8.745465278625488, 'learning_rate': 2.507518550134612e-05, 'epoch': 0.1641604832884628}
{'loss': 0.535, 'grad_norm': 16.80516815185547, 'learning_rate': 2.409022260161534e-05, 'epoch': 0.19699257994615535}
{'loss': 0.5013, 'grad_norm': 27.141977310180664, 'learning_rate': 2.310525970188456e-05, 'epoch': 0.22982467660384792}
{'loss': 0.4705, 'grad_norm': 15.195512771606445, 'learning_rate': 2.2120296802153785e-05, 'epoch': 0.26265677326154047}
{'loss': 0.4367, 'grad_norm': 5.321469783782959, 'learning_rate': 2.1135333902423008e-05, 'epoch': 0.29548886991923307}
{'loss': 0.4036, 'grad_norm': 5.117527961730957, 'learning_rate': 2.0150371002692233e-05, 'epoch': 0.3283209665769256}
{'loss': 0.3577, 'grad_norm': 3.9494290351867676, 'learning_rate': 1.9165408102961456e-05, 'epoch': 0.36115306323461815}
{'loss': 0.393, 'grad_norm': 21.11760139465332, 'learning_rate': 1.8180445203230678e-05, 'epoch': 0.3939851598923107}
{'loss': 0.3433, 'grad_norm': 10.480021476745605, 'learning_rate': 1.7195482303499903e-05, 'epoch': 0.4268172565500033}
{'loss': 0.3171, 'grad_norm': 18.612041473388672, 'learning_rate': 1.6210519403769126e-05, 'epoch': 0.45964935320769584}
{'loss': 0.3145, 'grad_norm': 6.835564613342285, 'learning_rate': 1.5225556504038348e-05, 'epoch': 0.4924814498653884}
{'loss': 0.2981, 'grad_norm': 15.075976371765137, 'learning_rate': 1.424059360430757e-05, 'epoch': 0.5253135465230809}
{'loss': 0.297, 'grad_norm': 2.037789821624756, 'learning_rate': 1.3255630704576794e-05, 'epoch': 0.5581456431807735}
{'loss': 0.2597, 'grad_norm': 12.717986106872559, 'learning_rate': 1.2270667804846018e-05, 'epoch': 0.5909777398384661}
{'loss': 0.2328, 'grad_norm': 3.1835501194000244, 'learning_rate': 1.1285704905115242e-05, 'epoch': 0.6238098364961586}
{'loss': 0.2279, 'grad_norm': 17.42547607421875, 'learning_rate': 1.0300742005384464e-05, 'epoch': 0.6566419331538512}
{'loss': 0.2243, 'grad_norm': 23.036142349243164, 'learning_rate': 9.315779105653688e-06, 'epoch': 0.6894740298115438}
{'loss': 0.2239, 'grad_norm': 11.325774192810059, 'learning_rate': 8.33081620592291e-06, 'epoch': 0.7223061264692363}
{'loss': 0.2007, 'grad_norm': 16.132965087890625, 'learning_rate': 7.345853306192133e-06, 'epoch': 0.7551382231269289}
{'loss': 0.2061, 'grad_norm': 10.584433555603027, 'learning_rate': 6.3608904064613565e-06, 'epoch': 0.7879703197846214}
{'loss': 0.1927, 'grad_norm': 4.951061725616455, 'learning_rate': 5.37592750673058e-06, 'epoch': 0.820802416442314}
{'loss': 0.1911, 'grad_norm': 10.373687744140625, 'learning_rate': 4.390964606999803e-06, 'epoch': 0.8536345131000066}
{'loss': 0.1746, 'grad_norm': 9.198591232299805, 'learning_rate': 3.406001707269026e-06, 'epoch': 0.8864666097576991}
{'loss': 0.1791, 'grad_norm': 18.606033325195312, 'learning_rate': 2.4210388075382497e-06, 'epoch': 0.9192987064153917}
{'loss': 0.1704, 'grad_norm': 11.76601505279541, 'learning_rate': 1.4360759078074728e-06, 'epoch': 0.9521308030730843}
{'loss': 0.1678, 'grad_norm': 25.40548324584961, 'learning_rate': 4.511130080766958e-07, 'epoch': 0.9849628997307768}
{'eval_loss': 0.8255599141120911, 'eval_runtime': 1052.4337, 'eval_samples_per_second': 179.809, 'eval_steps_per_second': 0.703, 'epoch': 1.0}
{'train_runtime': 5160.9845, 'train_samples_per_second': 47.211, 'train_steps_per_second': 2.951, 'train_loss': 0.36874321440277713, 'epoch': 1.0}
Post-processing 172858 example predictions split into 478989 features.
{
    "119": {
        "QA": {
            "exact_match": 28.787423220652034,
            "f1": 69.92206278398578
        },
        "PR": {
            "p@1": 0.9583136463210343,
            "p@2": 0.9928267686095958,
            "p@3": 0.996649628452386
        },
        "PRQA": {
            "exact_match": 27.692109445470557,
            "f1": 68.2645174327155
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 2662471 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 2662471 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
