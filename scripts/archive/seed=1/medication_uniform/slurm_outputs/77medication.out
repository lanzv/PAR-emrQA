2024-05-09 15:16:06 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 77 ---------------
2024-05-09 15:16:06 INFO     Contexts were splited into 1288 paragraphs, which are 7.038251366120218 paragraphs on average per one report. The overall paragraph average length (characters) is 934.2197204968944
2024-05-09 15:16:06 INFO     Contexts were splited into 194 paragraphs, which are 7.461538461538462 paragraphs on average per one report. The overall paragraph average length (characters) is 933.5773195876288
2024-05-09 15:16:06 INFO     Contexts were splited into 361 paragraphs, which are 6.811320754716981 paragraphs on average per one report. The overall paragraph average length (characters) is 939.0083102493074
2024-05-09 15:16:14 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-09 15:17:26 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-09 15:40:06 INFO     the model is trained
2024-05-09 15:45:06 INFO     evaluation data are prepared
2024-05-09 16:48:12 INFO     QA scores: {'exact_match': 29.902066062454363, 'f1': 73.80963164676066}
2024-05-09 16:48:12 INFO     PR scores: {'p@1': 0.8826296121300632, 'p@2': 0.9754306086508312, 'p@3': 0.9949744426785792}
2024-05-09 16:48:14 INFO     PRQA scores: {'exact_match': 28.630643013616254, 'f1': 69.12011008471144}
{'loss': 1.718, 'grad_norm': 13.928141593933105, 'learning_rate': 2.6426869938065744e-05, 'epoch': 0.11910433539780849}
{'loss': 1.1002, 'grad_norm': 15.398597717285156, 'learning_rate': 2.2853739876131495e-05, 'epoch': 0.23820867079561697}
{'loss': 0.9375, 'grad_norm': 8.907120704650879, 'learning_rate': 1.928060981419724e-05, 'epoch': 0.35731300619342543}
{'loss': 0.7754, 'grad_norm': 13.523904800415039, 'learning_rate': 1.5707479752262982e-05, 'epoch': 0.47641734159123394}
{'loss': 0.657, 'grad_norm': 8.051185607910156, 'learning_rate': 1.2134349690328729e-05, 'epoch': 0.5955216769890423}
{'loss': 0.5643, 'grad_norm': 9.698328018188477, 'learning_rate': 8.561219628394474e-06, 'epoch': 0.7146260123868509}
{'loss': 0.4835, 'grad_norm': 12.688220024108887, 'learning_rate': 4.9880895664602195e-06, 'epoch': 0.8337303477846594}
{'loss': 0.4385, 'grad_norm': 14.082273483276367, 'learning_rate': 1.4149595045259648e-06, 'epoch': 0.9528346831824679}
{'eval_loss': 1.8416999578475952, 'eval_runtime': 236.0052, 'eval_samples_per_second': 181.695, 'eval_steps_per_second': 0.712, 'epoch': 1.0}
{'train_runtime': 1359.318, 'train_samples_per_second': 49.409, 'train_steps_per_second': 3.088, 'train_loss': 0.8171274822175134, 'epoch': 1.0}
Post-processing 354547 example predictions split into 370182 features.
{
    "77": {
        "QA": {
            "exact_match": 29.902066062454363,
            "f1": 73.80963164676066
        },
        "PR": {
            "p@1": 0.8826296121300632,
            "p@2": 0.9754306086508312,
            "p@3": 0.9949744426785792
        },
        "PRQA": {
            "exact_match": 28.630643013616254,
            "f1": 69.12011008471144
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 1206810 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 1206810 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
