2024-05-09 19:10:09 INFO     ------------- Experiment: model BERTbase, frequency threshold 119 ---------------
2024-05-09 19:10:09 INFO     Contexts were splited into 663 paragraphs, which are 3.622950819672131 paragraphs on average per one report. The overall paragraph average length (characters) is 1814.894419306184
2024-05-09 19:10:09 INFO     Contexts were splited into 101 paragraphs, which are 3.8846153846153846 paragraphs on average per one report. The overall paragraph average length (characters) is 1793.2079207920792
2024-05-09 19:10:10 INFO     Contexts were splited into 185 paragraphs, which are 3.490566037735849 paragraphs on average per one report. The overall paragraph average length (characters) is 1832.335135135135
2024-05-09 19:10:17 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-09 19:12:39 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-09 20:05:23 INFO     the model is trained
2024-05-09 20:10:53 INFO     evaluation data are prepared
2024-05-09 21:24:29 INFO     QA scores: {'exact_match': 29.139641767965294, 'f1': 70.36504702297367}
2024-05-09 21:24:30 INFO     PR scores: {'p@1': 0.9090245264378678, 'p@2': 0.9862119324771272, 'p@3': 0.9963704308234183}
2024-05-09 21:24:32 INFO     PRQA scores: {'exact_match': 27.967011726300417, 'f1': 67.15248427474482}
{'loss': 1.515, 'grad_norm': 15.192717552185059, 'learning_rate': 2.8471882640586798e-05, 'epoch': 0.05093724531377343}
{'loss': 0.9897, 'grad_norm': 13.578492164611816, 'learning_rate': 2.6943765281173595e-05, 'epoch': 0.10187449062754686}
{'loss': 0.8845, 'grad_norm': 11.214472770690918, 'learning_rate': 2.5415647921760392e-05, 'epoch': 0.1528117359413203}
{'loss': 0.7448, 'grad_norm': 18.660011291503906, 'learning_rate': 2.3887530562347186e-05, 'epoch': 0.20374898125509372}
{'loss': 0.6927, 'grad_norm': 13.277443885803223, 'learning_rate': 2.2359413202933983e-05, 'epoch': 0.25468622656886714}
{'loss': 0.6295, 'grad_norm': 19.384737014770508, 'learning_rate': 2.083129584352078e-05, 'epoch': 0.3056234718826406}
{'loss': 0.5767, 'grad_norm': 10.2110595703125, 'learning_rate': 1.930317848410758e-05, 'epoch': 0.356560717196414}
{'loss': 0.5101, 'grad_norm': 15.36139965057373, 'learning_rate': 1.777506112469438e-05, 'epoch': 0.40749796251018744}
{'loss': 0.4867, 'grad_norm': 10.300459861755371, 'learning_rate': 1.6246943765281176e-05, 'epoch': 0.45843520782396086}
{'loss': 0.4586, 'grad_norm': 13.808531761169434, 'learning_rate': 1.4718826405867971e-05, 'epoch': 0.5093724531377343}
{'loss': 0.4214, 'grad_norm': 15.724715232849121, 'learning_rate': 1.3190709046454768e-05, 'epoch': 0.5603096984515077}
{'loss': 0.3827, 'grad_norm': 18.475793838500977, 'learning_rate': 1.1662591687041566e-05, 'epoch': 0.6112469437652812}
{'loss': 0.3539, 'grad_norm': 13.160758018493652, 'learning_rate': 1.0134474327628361e-05, 'epoch': 0.6621841890790546}
{'loss': 0.3378, 'grad_norm': 9.103475570678711, 'learning_rate': 8.606356968215158e-06, 'epoch': 0.713121434392828}
{'loss': 0.3306, 'grad_norm': 10.071903228759766, 'learning_rate': 7.078239608801956e-06, 'epoch': 0.7640586797066015}
{'loss': 0.3019, 'grad_norm': 15.085810661315918, 'learning_rate': 5.550122249388753e-06, 'epoch': 0.8149959250203749}
{'loss': 0.292, 'grad_norm': 12.453103065490723, 'learning_rate': 4.022004889975551e-06, 'epoch': 0.8659331703341483}
{'loss': 0.2719, 'grad_norm': 13.951762199401855, 'learning_rate': 2.493887530562347e-06, 'epoch': 0.9168704156479217}
{'loss': 0.2576, 'grad_norm': 15.420645713806152, 'learning_rate': 9.657701711491443e-07, 'epoch': 0.9678076609616952}
{'eval_loss': 1.3154876232147217, 'eval_runtime': 519.3434, 'eval_samples_per_second': 180.152, 'eval_steps_per_second': 0.705, 'epoch': 1.0}
{'train_runtime': 3163.0162, 'train_samples_per_second': 49.651, 'train_steps_per_second': 3.103, 'train_loss': 0.5399664845423866, 'epoch': 1.0}
Post-processing 180439 example predictions split into 429501 features.
{
    "119": {
        "QA": {
            "exact_match": 29.139641767965294,
            "f1": 70.36504702297367
        },
        "PR": {
            "p@1": 0.9090245264378678,
            "p@2": 0.9862119324771272,
            "p@3": 0.9963704308234183
        },
        "PRQA": {
            "exact_match": 27.967011726300417,
            "f1": 67.15248427474482
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 490549 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 490549 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
