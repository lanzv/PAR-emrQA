2024-05-10 12:06:58 INFO     ------------- Experiment: model BERTbase, frequency threshold 190 ---------------
2024-05-10 12:06:58 INFO     Contexts were splited into 525 paragraphs, which are 1.761744966442953 paragraphs on average per one report. The overall paragraph average length (characters) is 3151.7542857142857
2024-05-10 12:06:58 INFO     Contexts were splited into 63 paragraphs, which are 1.5 paragraphs on average per one report. The overall paragraph average length (characters) is 2857.095238095238
2024-05-10 12:06:59 INFO     Contexts were splited into 140 paragraphs, which are 1.627906976744186 paragraphs on average per one report. The overall paragraph average length (characters) is 3012.692857142857
2024-05-10 12:07:30 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-10 12:15:14 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 14:14:12 INFO     the model is trained
2024-05-10 14:35:37 INFO     evaluation data are prepared
2024-05-10 18:51:46 INFO     QA scores: {'exact_match': 90.12692066856124, 'f1': 95.74885513600935}
2024-05-10 18:51:47 INFO     PR scores: {'p@1': 0.983653244063388, 'p@2': 0.9981034150570782, 'p@3': 0.9993678050190261}
2024-05-10 18:51:57 INFO     PRQA scores: {'exact_match': 89.1057752516738, 'f1': 94.8712026997148}
{'loss': 0.6247, 'grad_norm': 4.194867134094238, 'learning_rate': 2.9021271042672585e-05, 'epoch': 0.032624298577580584}
{'loss': 0.3376, 'grad_norm': 13.913818359375, 'learning_rate': 2.8042542085345166e-05, 'epoch': 0.06524859715516117}
{'loss': 0.2608, 'grad_norm': 13.861836433410645, 'learning_rate': 2.706381312801775e-05, 'epoch': 0.09787289573274174}
{'loss': 0.2563, 'grad_norm': 36.63710021972656, 'learning_rate': 2.608508417069033e-05, 'epoch': 0.13049719431032233}
{'loss': 0.2151, 'grad_norm': 1.9601353406906128, 'learning_rate': 2.5106355213362915e-05, 'epoch': 0.1631214928879029}
{'loss': 0.2087, 'grad_norm': 4.042952537536621, 'learning_rate': 2.4127626256035495e-05, 'epoch': 0.1957457914654835}
{'loss': 0.1923, 'grad_norm': 10.521536827087402, 'learning_rate': 2.314889729870808e-05, 'epoch': 0.22837009004306408}
{'loss': 0.166, 'grad_norm': 11.892035484313965, 'learning_rate': 2.2170168341380664e-05, 'epoch': 0.26099438862064467}
{'loss': 0.1757, 'grad_norm': 0.9774821400642395, 'learning_rate': 2.1191439384053244e-05, 'epoch': 0.29361868719822526}
{'loss': 0.1573, 'grad_norm': 6.850549221038818, 'learning_rate': 2.0212710426725825e-05, 'epoch': 0.3262429857758058}
{'loss': 0.1535, 'grad_norm': 34.91897964477539, 'learning_rate': 1.9233981469398406e-05, 'epoch': 0.3588672843533864}
{'loss': 0.1442, 'grad_norm': 21.424854278564453, 'learning_rate': 1.825525251207099e-05, 'epoch': 0.391491582930967}
{'loss': 0.1261, 'grad_norm': 10.512900352478027, 'learning_rate': 1.727652355474357e-05, 'epoch': 0.42411588150854757}
{'loss': 0.1281, 'grad_norm': 0.5518745183944702, 'learning_rate': 1.6297794597416155e-05, 'epoch': 0.45674018008612816}
{'loss': 0.1149, 'grad_norm': 11.829760551452637, 'learning_rate': 1.531906564008874e-05, 'epoch': 0.48936447866370875}
{'loss': 0.1215, 'grad_norm': 0.08672638982534409, 'learning_rate': 1.434033668276132e-05, 'epoch': 0.5219887772412893}
{'loss': 0.1144, 'grad_norm': 0.2176419198513031, 'learning_rate': 1.3361607725433904e-05, 'epoch': 0.5546130758188699}
{'loss': 0.1052, 'grad_norm': 1.4160579442977905, 'learning_rate': 1.2382878768106486e-05, 'epoch': 0.5872373743964505}
{'loss': 0.1024, 'grad_norm': 0.08923882246017456, 'learning_rate': 1.1404149810779069e-05, 'epoch': 0.619861672974031}
{'loss': 0.0955, 'grad_norm': 0.24210704863071442, 'learning_rate': 1.0425420853451651e-05, 'epoch': 0.6524859715516116}
{'loss': 0.0962, 'grad_norm': 15.908075332641602, 'learning_rate': 9.446691896124233e-06, 'epoch': 0.6851102701291922}
{'loss': 0.0912, 'grad_norm': 10.943828582763672, 'learning_rate': 8.467962938796816e-06, 'epoch': 0.7177345687067728}
{'loss': 0.0878, 'grad_norm': 0.08386894315481186, 'learning_rate': 7.489233981469398e-06, 'epoch': 0.7503588672843534}
{'loss': 0.0842, 'grad_norm': 0.04612911492586136, 'learning_rate': 6.510505024141981e-06, 'epoch': 0.782983165861934}
{'loss': 0.0761, 'grad_norm': 0.1389799416065216, 'learning_rate': 5.531776066814564e-06, 'epoch': 0.8156074644395146}
{'loss': 0.0782, 'grad_norm': 7.902055263519287, 'learning_rate': 4.553047109487146e-06, 'epoch': 0.8482317630170951}
{'loss': 0.0764, 'grad_norm': 0.20720742642879486, 'learning_rate': 3.5743181521597284e-06, 'epoch': 0.8808560615946757}
{'loss': 0.0672, 'grad_norm': 0.0547247976064682, 'learning_rate': 2.5955891948323113e-06, 'epoch': 0.9134803601722563}
{'loss': 0.0598, 'grad_norm': 7.136882781982422, 'learning_rate': 1.6168602375048937e-06, 'epoch': 0.9461046587498368}
{'loss': 0.0634, 'grad_norm': 1.055742621421814, 'learning_rate': 6.381312801774762e-07, 'epoch': 0.9787289573274175}
{'eval_loss': 0.29035478830337524, 'eval_runtime': 3031.1693, 'eval_samples_per_second': 180.243, 'eval_steps_per_second': 0.704, 'epoch': 1.0}
{'train_runtime': 7136.7363, 'train_samples_per_second': 34.359, 'train_steps_per_second': 2.147, 'train_loss': 0.15099863736604285, 'epoch': 1.0}
Post-processing 373252 example predictions split into 1504802 features.
{
    "190": {
        "QA": {
            "exact_match": 90.12692066856124,
            "f1": 95.74885513600935
        },
        "PR": {
            "p@1": 0.983653244063388,
            "p@2": 0.9981034150570782,
            "p@3": 0.9993678050190261
        },
        "PRQA": {
            "exact_match": 89.1057752516738,
            "f1": 94.8712026997148
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 708455 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 708455 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
