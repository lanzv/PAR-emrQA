2024-05-10 05:28:45 INFO     ------------- Experiment: model BERTbase, frequency threshold 134 ---------------
2024-05-10 05:28:45 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-10 05:28:45 INFO     Contexts were splited into 1585 paragraphs, which are 5.318791946308725 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 1064.9192429022082
2024-05-10 05:28:45 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-10 05:28:46 INFO     Contexts were splited into 204 paragraphs, which are 4.857142857142857 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 900.3333333333334
2024-05-10 05:28:46 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-10 05:28:46 INFO     Contexts were splited into 428 paragraphs, which are 4.976744186046512 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 1005.4649532710281
2024-05-10 05:29:25 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-10 05:37:10 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 07:48:14 INFO     the model is trained
2024-05-10 08:13:31 INFO     evaluation data are prepared
2024-05-10 13:52:25 INFO     QA scores: {'exact_match': 89.65608593035017, 'f1': 95.30651088671034}
2024-05-10 13:52:25 INFO     PR scores: {'p@1': 0.9840927700977795, 'p@2': 0.9980672896295939, 'p@3': 0.9999277491450316}
2024-05-10 13:52:35 INFO     PRQA scores: {'exact_match': 88.43504648138337, 'f1': 94.29778414114631}
{'loss': 0.5878, 'grad_norm': 20.875375747680664, 'learning_rate': 2.9120647203658107e-05, 'epoch': 0.02931175987806308}
{'loss': 0.2972, 'grad_norm': 5.261601448059082, 'learning_rate': 2.8241294407316217e-05, 'epoch': 0.05862351975612616}
{'loss': 0.2501, 'grad_norm': 5.631280422210693, 'learning_rate': 2.7361941610974323e-05, 'epoch': 0.08793527963418923}
{'loss': 0.2199, 'grad_norm': 7.6601881980896, 'learning_rate': 2.648258881463243e-05, 'epoch': 0.11724703951225232}
{'loss': 0.2068, 'grad_norm': 9.760688781738281, 'learning_rate': 2.560323601829054e-05, 'epoch': 0.14655879939031538}
{'loss': 0.1885, 'grad_norm': 0.8811495900154114, 'learning_rate': 2.4723883221948645e-05, 'epoch': 0.17587055926837847}
{'loss': 0.1763, 'grad_norm': 5.968023777008057, 'learning_rate': 2.384453042560675e-05, 'epoch': 0.20518231914644156}
{'loss': 0.1948, 'grad_norm': 3.919220447540283, 'learning_rate': 2.2965177629264865e-05, 'epoch': 0.23449407902450464}
{'loss': 0.1638, 'grad_norm': 11.755441665649414, 'learning_rate': 2.208582483292297e-05, 'epoch': 0.2638058389025677}
{'loss': 0.1518, 'grad_norm': 1.1354482173919678, 'learning_rate': 2.1206472036581077e-05, 'epoch': 0.29311759878063076}
{'loss': 0.1398, 'grad_norm': 16.562944412231445, 'learning_rate': 2.0327119240239187e-05, 'epoch': 0.3224293586586939}
{'loss': 0.155, 'grad_norm': 0.2632967531681061, 'learning_rate': 1.9447766443897293e-05, 'epoch': 0.35174111853675694}
{'loss': 0.1369, 'grad_norm': 21.049274444580078, 'learning_rate': 1.85684136475554e-05, 'epoch': 0.38105287841482005}
{'loss': 0.1331, 'grad_norm': 9.611917495727539, 'learning_rate': 1.768906085121351e-05, 'epoch': 0.4103646382928831}
{'loss': 0.1309, 'grad_norm': 11.070884704589844, 'learning_rate': 1.6809708054871615e-05, 'epoch': 0.43967639817094617}
{'loss': 0.1163, 'grad_norm': 10.09778881072998, 'learning_rate': 1.5930355258529722e-05, 'epoch': 0.4689881580490093}
{'loss': 0.1073, 'grad_norm': 6.902170658111572, 'learning_rate': 1.5051002462187831e-05, 'epoch': 0.49829991792707234}
{'loss': 0.1093, 'grad_norm': 0.8829429745674133, 'learning_rate': 1.4171649665845938e-05, 'epoch': 0.5276116778051354}
{'loss': 0.1154, 'grad_norm': 9.360695838928223, 'learning_rate': 1.3292296869504044e-05, 'epoch': 0.5569234376831985}
{'loss': 0.0948, 'grad_norm': 0.9810887575149536, 'learning_rate': 1.2412944073162154e-05, 'epoch': 0.5862351975612615}
{'loss': 0.0946, 'grad_norm': 0.6299299597740173, 'learning_rate': 1.1533591276820262e-05, 'epoch': 0.6155469574393246}
{'loss': 0.1033, 'grad_norm': 0.10102739185094833, 'learning_rate': 1.0654238480478368e-05, 'epoch': 0.6448587173173878}
{'loss': 0.089, 'grad_norm': 0.017345279455184937, 'learning_rate': 9.774885684136476e-06, 'epoch': 0.6741704771954509}
{'loss': 0.0975, 'grad_norm': 0.03036574274301529, 'learning_rate': 8.895532887794584e-06, 'epoch': 0.7034822370735139}
{'loss': 0.0757, 'grad_norm': 1.9090404510498047, 'learning_rate': 8.01618009145269e-06, 'epoch': 0.732793996951577}
{'loss': 0.0817, 'grad_norm': 0.017285581678152084, 'learning_rate': 7.136827295110799e-06, 'epoch': 0.7621057568296401}
{'loss': 0.0751, 'grad_norm': 30.358287811279297, 'learning_rate': 6.257474498768906e-06, 'epoch': 0.7914175167077031}
{'loss': 0.0664, 'grad_norm': 0.08477184176445007, 'learning_rate': 5.378121702427013e-06, 'epoch': 0.8207292765857662}
{'loss': 0.0685, 'grad_norm': 0.41255322098731995, 'learning_rate': 4.498768906085121e-06, 'epoch': 0.8500410364638293}
{'loss': 0.066, 'grad_norm': 4.579010963439941, 'learning_rate': 3.619416109743229e-06, 'epoch': 0.8793527963418923}
{'loss': 0.0786, 'grad_norm': 32.3050537109375, 'learning_rate': 2.740063313401337e-06, 'epoch': 0.9086645562199555}
{'loss': 0.0666, 'grad_norm': 0.8532636165618896, 'learning_rate': 1.860710517059444e-06, 'epoch': 0.9379763160980186}
{'loss': 0.0622, 'grad_norm': 0.02061556465923786, 'learning_rate': 9.813577207175519e-07, 'epoch': 0.9672880759760816}
{'loss': 0.0717, 'grad_norm': 12.134160041809082, 'learning_rate': 1.0200492437565952e-07, 'epoch': 0.9965998358541447}
{'eval_loss': 0.2847166657447815, 'eval_runtime': 3325.4817, 'eval_samples_per_second': 183.12, 'eval_steps_per_second': 0.715, 'epoch': 1.0}
{'train_runtime': 7862.4685, 'train_samples_per_second': 34.712, 'train_steps_per_second': 2.17, 'train_loss': 0.1401358894704165, 'epoch': 1.0}
Post-processing 897369 example predictions split into 2047141 features.
{
    "134": {
        "QA": {
            "exact_match": 89.65608593035017,
            "f1": 95.30651088671034
        },
        "PR": {
            "p@1": 0.9840927700977795,
            "p@2": 0.9980672896295939,
            "p@3": 0.9999277491450316
        },
        "PRQA": {
            "exact_match": 88.43504648138337,
            "f1": 94.29778414114631
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 2742882 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 2742882 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
