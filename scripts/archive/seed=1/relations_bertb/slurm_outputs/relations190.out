2024-05-10 04:25:38 INFO     ------------- Experiment: model BERTbase, frequency threshold 190 ---------------
2024-05-10 04:25:39 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-10 04:25:39 INFO     Contexts were splited into 495 paragraphs, which are 1.6610738255033557 paragraphs on average per one report. There are 1 unique topics with frequency threshold (greater or equal) 190. The overall paragraph average length (characters) is 3409.8929292929292
2024-05-10 04:25:39 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-10 04:25:39 INFO     Contexts were splited into 69 paragraphs, which are 1.6428571428571428 paragraphs on average per one report. There are 1 unique topics with frequency threshold (greater or equal) 190. The overall paragraph average length (characters) is 2661.855072463768
2024-05-10 04:25:40 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-10 04:25:40 INFO     Contexts were splited into 141 paragraphs, which are 1.6395348837209303 paragraphs on average per one report. There are 1 unique topics with frequency threshold (greater or equal) 190. The overall paragraph average length (characters) is 3052.049645390071
2024-05-10 04:26:17 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-10 04:36:25 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 07:18:12 INFO     the model is trained
2024-05-10 07:39:44 INFO     evaluation data are prepared
2024-05-10 12:12:14 INFO     QA scores: {'exact_match': 87.89376715957806, 'f1': 94.3991166195461}
2024-05-10 12:12:14 INFO     PR scores: {'p@1': 0.9962188719233177, 'p@2': 1.0, 'p@3': 1.0}
2024-05-10 12:12:24 INFO     PRQA scores: {'exact_match': 87.69206685612447, 'f1': 94.22078729212382}
{'loss': 0.5627, 'grad_norm': 4.654568672180176, 'learning_rate': 2.930007932434324e-05, 'epoch': 0.02333068918855863}
{'loss': 0.2928, 'grad_norm': 2.955946683883667, 'learning_rate': 2.8600158648686484e-05, 'epoch': 0.04666137837711726}
{'loss': 0.2456, 'grad_norm': 10.386290550231934, 'learning_rate': 2.7900237973029724e-05, 'epoch': 0.06999206756567589}
{'loss': 0.2317, 'grad_norm': 1.987630844116211, 'learning_rate': 2.7200317297372964e-05, 'epoch': 0.09332275675423451}
{'loss': 0.2128, 'grad_norm': 8.934028625488281, 'learning_rate': 2.6500396621716207e-05, 'epoch': 0.11665344594279314}
{'loss': 0.2158, 'grad_norm': 4.02716588973999, 'learning_rate': 2.5800475946059447e-05, 'epoch': 0.13998413513135177}
{'loss': 0.1961, 'grad_norm': 12.072338104248047, 'learning_rate': 2.510055527040269e-05, 'epoch': 0.1633148243199104}
{'loss': 0.1777, 'grad_norm': 3.637772560119629, 'learning_rate': 2.440063459474593e-05, 'epoch': 0.18664551350846903}
{'loss': 0.1612, 'grad_norm': 10.699922561645508, 'learning_rate': 2.370071391908917e-05, 'epoch': 0.20997620269702766}
{'loss': 0.1648, 'grad_norm': 13.34153938293457, 'learning_rate': 2.3000793243432413e-05, 'epoch': 0.2333068918855863}
{'loss': 0.1556, 'grad_norm': 7.773183822631836, 'learning_rate': 2.2300872567775653e-05, 'epoch': 0.2566375810741449}
{'loss': 0.1663, 'grad_norm': 5.4545159339904785, 'learning_rate': 2.1600951892118893e-05, 'epoch': 0.27996827026270354}
{'loss': 0.1495, 'grad_norm': 0.1606619507074356, 'learning_rate': 2.0901031216462136e-05, 'epoch': 0.3032989594512622}
{'loss': 0.1317, 'grad_norm': 0.2028142809867859, 'learning_rate': 2.0201110540805376e-05, 'epoch': 0.3266296486398208}
{'loss': 0.1373, 'grad_norm': 0.5651237964630127, 'learning_rate': 1.9501189865148616e-05, 'epoch': 0.34996033782837943}
{'loss': 0.1423, 'grad_norm': 16.966388702392578, 'learning_rate': 1.880126918949186e-05, 'epoch': 0.37329102701693806}
{'loss': 0.1303, 'grad_norm': 13.79481029510498, 'learning_rate': 1.81013485138351e-05, 'epoch': 0.3966217162054967}
{'loss': 0.1254, 'grad_norm': 13.384754180908203, 'learning_rate': 1.7401427838178342e-05, 'epoch': 0.4199524053940553}
{'loss': 0.122, 'grad_norm': 12.060811996459961, 'learning_rate': 1.6701507162521582e-05, 'epoch': 0.44328309458261395}
{'loss': 0.1135, 'grad_norm': 0.06337182223796844, 'learning_rate': 1.6001586486864822e-05, 'epoch': 0.4666137837711726}
{'loss': 0.1071, 'grad_norm': 0.019298750907182693, 'learning_rate': 1.5301665811208065e-05, 'epoch': 0.4899444729597312}
{'loss': 0.1069, 'grad_norm': 0.22069783508777618, 'learning_rate': 1.4601745135551303e-05, 'epoch': 0.5132751621482898}
{'loss': 0.1113, 'grad_norm': 0.05873996019363403, 'learning_rate': 1.3901824459894545e-05, 'epoch': 0.5366058513368485}
{'loss': 0.0999, 'grad_norm': 14.222826957702637, 'learning_rate': 1.3201903784237787e-05, 'epoch': 0.5599365405254071}
{'loss': 0.104, 'grad_norm': 0.9532656073570251, 'learning_rate': 1.2501983108581027e-05, 'epoch': 0.5832672297139657}
{'loss': 0.1027, 'grad_norm': 5.128330707550049, 'learning_rate': 1.1802062432924268e-05, 'epoch': 0.6065979189025243}
{'loss': 0.0896, 'grad_norm': 10.666823387145996, 'learning_rate': 1.110214175726751e-05, 'epoch': 0.629928608091083}
{'loss': 0.0825, 'grad_norm': 0.009109417907893658, 'learning_rate': 1.0402221081610751e-05, 'epoch': 0.6532592972796416}
{'loss': 0.0847, 'grad_norm': 0.28904828429222107, 'learning_rate': 9.702300405953991e-06, 'epoch': 0.6765899864682002}
{'loss': 0.0858, 'grad_norm': 0.02424810454249382, 'learning_rate': 9.002379730297233e-06, 'epoch': 0.6999206756567589}
{'loss': 0.0795, 'grad_norm': 12.141265869140625, 'learning_rate': 8.302459054640474e-06, 'epoch': 0.7232513648453175}
{'loss': 0.0884, 'grad_norm': 6.776772499084473, 'learning_rate': 7.602538378983715e-06, 'epoch': 0.7465820540338761}
{'loss': 0.088, 'grad_norm': 0.6131911277770996, 'learning_rate': 6.902617703326956e-06, 'epoch': 0.7699127432224347}
{'loss': 0.0709, 'grad_norm': 19.951251983642578, 'learning_rate': 6.202697027670197e-06, 'epoch': 0.7932434324109934}
{'loss': 0.0737, 'grad_norm': 27.230329513549805, 'learning_rate': 5.502776352013438e-06, 'epoch': 0.816574121599552}
{'loss': 0.0656, 'grad_norm': 0.09092248231172562, 'learning_rate': 4.80285567635668e-06, 'epoch': 0.8399048107881106}
{'loss': 0.0614, 'grad_norm': 0.2002050131559372, 'learning_rate': 4.10293500069992e-06, 'epoch': 0.8632354999766693}
{'loss': 0.0697, 'grad_norm': 0.05555177852511406, 'learning_rate': 3.403014325043162e-06, 'epoch': 0.8865661891652279}
{'loss': 0.0682, 'grad_norm': 1.802192211151123, 'learning_rate': 2.7030936493864026e-06, 'epoch': 0.9098968783537865}
{'loss': 0.0686, 'grad_norm': 1.4742450714111328, 'learning_rate': 2.0031729737296438e-06, 'epoch': 0.9332275675423451}
{'loss': 0.0628, 'grad_norm': 18.309892654418945, 'learning_rate': 1.3032522980728851e-06, 'epoch': 0.9565582567309038}
{'loss': 0.0599, 'grad_norm': 22.837797164916992, 'learning_rate': 6.033316224161262e-07, 'epoch': 0.9798889459194624}
{'eval_loss': 0.2655470073223114, 'eval_runtime': 3983.1111, 'eval_samples_per_second': 181.766, 'eval_steps_per_second': 0.71, 'epoch': 1.0}
{'train_runtime': 9705.5331, 'train_samples_per_second': 35.329, 'train_steps_per_second': 2.208, 'train_loss': 0.1334296018198097, 'epoch': 1.0}
Post-processing 290387 example predictions split into 1625210 features.
{
    "190": {
        "QA": {
            "exact_match": 87.89376715957806,
            "f1": 94.3991166195461
        },
        "PR": {
            "p@1": 0.9962188719233177,
            "p@2": 1.0,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 87.69206685612447,
            "f1": 94.22078729212382
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3175293 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3175293 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
