2024-05-10 04:33:52 INFO     ------------- Experiment: model BERTbase, frequency threshold 154 ---------------
2024-05-10 04:33:52 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-10 04:33:52 INFO     Contexts were splited into 711 paragraphs, which are 2.3859060402684564 paragraphs on average per one report. There are 3 unique topics with frequency threshold (greater or equal) 154. The overall paragraph average length (characters) is 2373.9760900140645
2024-05-10 04:33:52 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-10 04:33:52 INFO     Contexts were splited into 110 paragraphs, which are 2.619047619047619 paragraphs on average per one report. There are 3 unique topics with frequency threshold (greater or equal) 154. The overall paragraph average length (characters) is 1669.709090909091
2024-05-10 04:33:53 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-10 04:33:53 INFO     Contexts were splited into 214 paragraphs, which are 2.488372093023256 paragraphs on average per one report. There are 3 unique topics with frequency threshold (greater or equal) 154. The overall paragraph average length (characters) is 2010.9299065420562
2024-05-10 04:34:32 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-10 04:44:44 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 07:32:18 INFO     the model is trained
2024-05-10 07:54:53 INFO     evaluation data are prepared
2024-05-10 12:47:21 INFO     QA scores: {'exact_match': 88.78907567072876, 'f1': 94.79379732715506}
2024-05-10 12:47:21 INFO     PR scores: {'p@1': 0.9953036944270507, 'p@2': 1.0, 'p@3': 1.0}
2024-05-10 12:47:31 INFO     PRQA scores: {'exact_match': 88.60483599055922, 'f1': 94.61093426173332}
{'loss': 0.6256, 'grad_norm': 10.927905082702637, 'learning_rate': 2.931189504105693e-05, 'epoch': 0.022936831964769026}
{'loss': 0.2816, 'grad_norm': 10.435986518859863, 'learning_rate': 2.862379008211386e-05, 'epoch': 0.04587366392953805}
{'loss': 0.249, 'grad_norm': 3.518554925918579, 'learning_rate': 2.7935685123170788e-05, 'epoch': 0.06881049589430707}
{'loss': 0.209, 'grad_norm': 4.433073043823242, 'learning_rate': 2.7247580164227717e-05, 'epoch': 0.0917473278590761}
{'loss': 0.211, 'grad_norm': 3.1288950443267822, 'learning_rate': 2.6559475205284646e-05, 'epoch': 0.11468415982384512}
{'loss': 0.1925, 'grad_norm': 1.8688793182373047, 'learning_rate': 2.5871370246341575e-05, 'epoch': 0.13762099178861414}
{'loss': 0.1779, 'grad_norm': 0.20502904057502747, 'learning_rate': 2.5183265287398503e-05, 'epoch': 0.16055782375338318}
{'loss': 0.1795, 'grad_norm': 23.983890533447266, 'learning_rate': 2.4495160328455436e-05, 'epoch': 0.1834946557181522}
{'loss': 0.1818, 'grad_norm': 47.95088195800781, 'learning_rate': 2.3807055369512365e-05, 'epoch': 0.20643148768292124}
{'loss': 0.1568, 'grad_norm': 4.289472579956055, 'learning_rate': 2.3118950410569294e-05, 'epoch': 0.22936831964769025}
{'loss': 0.171, 'grad_norm': 1.164171814918518, 'learning_rate': 2.2430845451626223e-05, 'epoch': 0.2523051516124593}
{'loss': 0.1558, 'grad_norm': 0.06073145568370819, 'learning_rate': 2.174274049268315e-05, 'epoch': 0.2752419835772283}
{'loss': 0.1509, 'grad_norm': 6.151655197143555, 'learning_rate': 2.105463553374008e-05, 'epoch': 0.2981788155419973}
{'loss': 0.1446, 'grad_norm': 0.7436078786849976, 'learning_rate': 2.036653057479701e-05, 'epoch': 0.32111564750676636}
{'loss': 0.1407, 'grad_norm': 22.99243927001953, 'learning_rate': 1.967842561585394e-05, 'epoch': 0.3440524794715354}
{'loss': 0.1257, 'grad_norm': 0.1988353729248047, 'learning_rate': 1.8990320656910868e-05, 'epoch': 0.3669893114363044}
{'loss': 0.1314, 'grad_norm': 37.0152473449707, 'learning_rate': 1.8302215697967797e-05, 'epoch': 0.38992614340107346}
{'loss': 0.1197, 'grad_norm': 0.5615279078483582, 'learning_rate': 1.7614110739024725e-05, 'epoch': 0.4128629753658425}
{'loss': 0.1198, 'grad_norm': 0.023342572152614594, 'learning_rate': 1.6926005780081654e-05, 'epoch': 0.4357998073306115}
{'loss': 0.1223, 'grad_norm': 0.1455831527709961, 'learning_rate': 1.6237900821138583e-05, 'epoch': 0.4587366392953805}
{'loss': 0.1087, 'grad_norm': 0.432565838098526, 'learning_rate': 1.5549795862195512e-05, 'epoch': 0.48167347126014953}
{'loss': 0.1049, 'grad_norm': 0.05275364965200424, 'learning_rate': 1.4861690903252443e-05, 'epoch': 0.5046103032249186}
{'loss': 0.1065, 'grad_norm': 8.934122085571289, 'learning_rate': 1.4173585944309372e-05, 'epoch': 0.5275471351896877}
{'loss': 0.1047, 'grad_norm': 13.420804023742676, 'learning_rate': 1.3485480985366301e-05, 'epoch': 0.5504839671544566}
{'loss': 0.092, 'grad_norm': 0.05190788581967354, 'learning_rate': 1.279737602642323e-05, 'epoch': 0.5734207991192256}
{'loss': 0.0823, 'grad_norm': 27.141801834106445, 'learning_rate': 1.2109271067480159e-05, 'epoch': 0.5963576310839946}
{'loss': 0.0927, 'grad_norm': 3.4284045696258545, 'learning_rate': 1.142116610853709e-05, 'epoch': 0.6192944630487637}
{'loss': 0.0932, 'grad_norm': 0.21484950184822083, 'learning_rate': 1.0733061149594018e-05, 'epoch': 0.6422312950135327}
{'loss': 0.0906, 'grad_norm': 14.939687728881836, 'learning_rate': 1.0044956190650947e-05, 'epoch': 0.6651681269783017}
{'loss': 0.095, 'grad_norm': 0.05305140092968941, 'learning_rate': 9.356851231707876e-06, 'epoch': 0.6881049589430708}
{'loss': 0.076, 'grad_norm': 19.862014770507812, 'learning_rate': 8.668746272764805e-06, 'epoch': 0.7110417909078398}
{'loss': 0.081, 'grad_norm': 0.05878186970949173, 'learning_rate': 7.980641313821734e-06, 'epoch': 0.7339786228726088}
{'loss': 0.0768, 'grad_norm': 0.21395240724086761, 'learning_rate': 7.292536354878665e-06, 'epoch': 0.7569154548373779}
{'loss': 0.0763, 'grad_norm': 0.04171987995505333, 'learning_rate': 6.604431395935594e-06, 'epoch': 0.7798522868021469}
{'loss': 0.0875, 'grad_norm': 17.989295959472656, 'learning_rate': 5.916326436992523e-06, 'epoch': 0.8027891187669159}
{'loss': 0.0722, 'grad_norm': 0.1381017416715622, 'learning_rate': 5.228221478049452e-06, 'epoch': 0.825725950731685}
{'loss': 0.0707, 'grad_norm': 5.977047443389893, 'learning_rate': 4.540116519106382e-06, 'epoch': 0.848662782696454}
{'loss': 0.0635, 'grad_norm': 0.269334614276886, 'learning_rate': 3.852011560163311e-06, 'epoch': 0.871599614661223}
{'loss': 0.058, 'grad_norm': 0.010849131271243095, 'learning_rate': 3.1639066012202396e-06, 'epoch': 0.894536446625992}
{'loss': 0.0564, 'grad_norm': 0.06850966066122055, 'learning_rate': 2.475801642277169e-06, 'epoch': 0.917473278590761}
{'loss': 0.0617, 'grad_norm': 7.5683159828186035, 'learning_rate': 1.787696683334098e-06, 'epoch': 0.94041011055553}
{'loss': 0.0588, 'grad_norm': 14.838613510131836, 'learning_rate': 1.0995917243910273e-06, 'epoch': 0.9633469425202991}
{'loss': 0.0589, 'grad_norm': 5.111178398132324, 'learning_rate': 4.1148676544795634e-07, 'epoch': 0.9862837744850681}
{'eval_loss': 0.24495667219161987, 'eval_runtime': 4143.7615, 'eval_samples_per_second': 178.256, 'eval_steps_per_second': 0.696, 'epoch': 1.0}
{'train_runtime': 10052.6905, 'train_samples_per_second': 34.695, 'train_steps_per_second': 2.168, 'train_loss': 0.13191724109006556, 'epoch': 1.0}
Post-processing 411873 example predictions split into 1739104 features.
{
    "154": {
        "QA": {
            "exact_match": 88.78907567072876,
            "f1": 94.79379732715506
        },
        "PR": {
            "p@1": 0.9953036944270507,
            "p@2": 1.0,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.60483599055922,
            "f1": 94.61093426173332
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 2664198 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 2664198 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
