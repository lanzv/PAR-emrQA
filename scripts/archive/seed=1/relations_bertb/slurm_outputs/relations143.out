2024-05-10 04:51:14 INFO     ------------- Experiment: model BERTbase, frequency threshold 143 ---------------
2024-05-10 04:51:14 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-10 04:51:14 INFO     Contexts were splited into 1160 paragraphs, which are 3.8926174496644297 paragraphs on average per one report. There are 6 unique topics with frequency threshold (greater or equal) 143. The overall paragraph average length (characters) is 1455.0836206896552
2024-05-10 04:51:15 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-10 04:51:15 INFO     Contexts were splited into 160 paragraphs, which are 3.8095238095238093 paragraphs on average per one report. There are 6 unique topics with frequency threshold (greater or equal) 143. The overall paragraph average length (characters) is 1147.925
2024-05-10 04:51:15 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-10 04:51:15 INFO     Contexts were splited into 323 paragraphs, which are 3.755813953488372 paragraphs on average per one report. There are 6 unique topics with frequency threshold (greater or equal) 143. The overall paragraph average length (characters) is 1332.3188854489165
2024-05-10 04:51:53 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-10 05:00:43 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 07:24:48 INFO     the model is trained
2024-05-10 07:48:46 INFO     evaluation data are prepared
2024-05-10 13:03:41 INFO     QA scores: {'exact_match': 89.76566639371899, 'f1': 95.31446579268905}
2024-05-10 13:03:42 INFO     PR scores: {'p@1': 0.9905532007128751, 'p@2': 0.9983021049082414, 'p@3': 1.0}
2024-05-10 13:03:51 INFO     PRQA scores: {'exact_match': 89.1057752516738, 'f1': 94.7758629804995}
{'loss': 0.6323, 'grad_norm': 9.788114547729492, 'learning_rate': 2.91941982272361e-05, 'epoch': 0.026860059092130004}
{'loss': 0.2941, 'grad_norm': 17.806365966796875, 'learning_rate': 2.83883964544722e-05, 'epoch': 0.05372011818426001}
{'loss': 0.2643, 'grad_norm': 21.36981964111328, 'learning_rate': 2.75825946817083e-05, 'epoch': 0.08058017727639001}
{'loss': 0.2112, 'grad_norm': 20.161190032958984, 'learning_rate': 2.67767929089444e-05, 'epoch': 0.10744023636852001}
{'loss': 0.1977, 'grad_norm': 2.9523799419403076, 'learning_rate': 2.59709911361805e-05, 'epoch': 0.13430029546065}
{'loss': 0.1909, 'grad_norm': 7.482027530670166, 'learning_rate': 2.51651893634166e-05, 'epoch': 0.16116035455278002}
{'loss': 0.1804, 'grad_norm': 10.91453742980957, 'learning_rate': 2.43593875906527e-05, 'epoch': 0.18802041364491}
{'loss': 0.1774, 'grad_norm': 8.389273643493652, 'learning_rate': 2.35535858178888e-05, 'epoch': 0.21488047273704003}
{'loss': 0.1626, 'grad_norm': 0.05638936534523964, 'learning_rate': 2.27477840451249e-05, 'epoch': 0.24174053182917002}
{'loss': 0.1641, 'grad_norm': 0.6238383054733276, 'learning_rate': 2.1941982272361e-05, 'epoch': 0.2686005909213}
{'loss': 0.1531, 'grad_norm': 1.107223391532898, 'learning_rate': 2.11361804995971e-05, 'epoch': 0.29546065001343}
{'loss': 0.1342, 'grad_norm': 0.18620392680168152, 'learning_rate': 2.03303787268332e-05, 'epoch': 0.32232070910556004}
{'loss': 0.1384, 'grad_norm': 2.837385416030884, 'learning_rate': 1.95245769540693e-05, 'epoch': 0.34918076819769006}
{'loss': 0.1257, 'grad_norm': 7.847644805908203, 'learning_rate': 1.87187751813054e-05, 'epoch': 0.37604082728982}
{'loss': 0.1201, 'grad_norm': 21.673992156982422, 'learning_rate': 1.79129734085415e-05, 'epoch': 0.40290088638195004}
{'loss': 0.1132, 'grad_norm': 26.968631744384766, 'learning_rate': 1.71071716357776e-05, 'epoch': 0.42976094547408006}
{'loss': 0.116, 'grad_norm': 17.545276641845703, 'learning_rate': 1.63013698630137e-05, 'epoch': 0.45662100456621}
{'loss': 0.1087, 'grad_norm': 5.327691555023193, 'learning_rate': 1.54955680902498e-05, 'epoch': 0.48348106365834004}
{'loss': 0.1109, 'grad_norm': 6.5493083000183105, 'learning_rate': 1.4689766317485899e-05, 'epoch': 0.51034112275047}
{'loss': 0.11, 'grad_norm': 0.5137096643447876, 'learning_rate': 1.3883964544721999e-05, 'epoch': 0.5372011818426}
{'loss': 0.0965, 'grad_norm': 3.9320030212402344, 'learning_rate': 1.3078162771958099e-05, 'epoch': 0.5640612409347301}
{'loss': 0.0942, 'grad_norm': 7.631316184997559, 'learning_rate': 1.2272360999194198e-05, 'epoch': 0.59092130002686}
{'loss': 0.0877, 'grad_norm': 0.9100648164749146, 'learning_rate': 1.1466559226430298e-05, 'epoch': 0.61778135911899}
{'loss': 0.0942, 'grad_norm': 7.554276943206787, 'learning_rate': 1.0660757453666398e-05, 'epoch': 0.6446414182111201}
{'loss': 0.0929, 'grad_norm': 0.230043426156044, 'learning_rate': 9.854955680902498e-06, 'epoch': 0.67150147730325}
{'loss': 0.0915, 'grad_norm': 4.5170488357543945, 'learning_rate': 9.049153908138598e-06, 'epoch': 0.6983615363953801}
{'loss': 0.1004, 'grad_norm': 3.9422688484191895, 'learning_rate': 8.243352135374698e-06, 'epoch': 0.7252215954875101}
{'loss': 0.086, 'grad_norm': 4.1552534103393555, 'learning_rate': 7.437550362610798e-06, 'epoch': 0.75208165457964}
{'loss': 0.078, 'grad_norm': 0.371671587228775, 'learning_rate': 6.631748589846899e-06, 'epoch': 0.7789417136717701}
{'loss': 0.0695, 'grad_norm': 0.08896012604236603, 'learning_rate': 5.825946817082998e-06, 'epoch': 0.8058017727639001}
{'loss': 0.0645, 'grad_norm': 0.060720980167388916, 'learning_rate': 5.0201450443190976e-06, 'epoch': 0.83266183185603}
{'loss': 0.0698, 'grad_norm': 0.06939484924077988, 'learning_rate': 4.2143432715551975e-06, 'epoch': 0.8595218909481601}
{'loss': 0.0701, 'grad_norm': 0.03894776105880737, 'learning_rate': 3.4085414987912974e-06, 'epoch': 0.8863819500402901}
{'loss': 0.0619, 'grad_norm': 0.07413607090711594, 'learning_rate': 2.6027397260273973e-06, 'epoch': 0.91324200913242}
{'loss': 0.0708, 'grad_norm': 19.434568405151367, 'learning_rate': 1.7969379532634972e-06, 'epoch': 0.9401020682245501}
{'loss': 0.0586, 'grad_norm': 0.26172491908073425, 'learning_rate': 9.91136180499597e-07, 'epoch': 0.9669621273166801}
{'loss': 0.0658, 'grad_norm': 0.01914878562092781, 'learning_rate': 1.8533440773569704e-07, 'epoch': 0.9938221864088101}
{'eval_loss': 0.27189961075782776, 'eval_runtime': 3612.1076, 'eval_samples_per_second': 179.323, 'eval_steps_per_second': 0.701, 'epoch': 1.0}
{'train_runtime': 8643.5433, 'train_samples_per_second': 34.457, 'train_steps_per_second': 2.154, 'train_loss': 0.13619151044974173, 'epoch': 1.0}
Post-processing 654532 example predictions split into 1865263 features.
{
    "143": {
        "QA": {
            "exact_match": 89.76566639371899,
            "f1": 95.31446579268905
        },
        "PR": {
            "p@1": 0.9905532007128751,
            "p@2": 0.9983021049082414,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 89.1057752516738,
            "f1": 94.7758629804995
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3660896 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3660896 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
