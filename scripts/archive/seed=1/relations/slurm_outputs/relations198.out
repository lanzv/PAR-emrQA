2024-05-09 23:35:11 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 198 ---------------
2024-05-09 23:35:11 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-09 23:35:11 INFO     Contexts were splited into 298 paragraphs, which are 1.0 paragraphs on average per one report. There are 0 unique topics with frequency threshold (greater or equal) 198. The overall paragraph average length (characters) is 5664.083892617449
2024-05-09 23:35:12 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-09 23:35:12 INFO     Contexts were splited into 42 paragraphs, which are 1.0 paragraphs on average per one report. There are 0 unique topics with frequency threshold (greater or equal) 198. The overall paragraph average length (characters) is 4373.047619047619
2024-05-09 23:35:12 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-09 23:35:12 INFO     Contexts were splited into 86 paragraphs, which are 1.0 paragraphs on average per one report. There are 0 unique topics with frequency threshold (greater or equal) 198. The overall paragraph average length (characters) is 5003.941860465116
2024-05-09 23:35:49 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-09 23:45:38 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-10 02:07:52 INFO     the model is trained
2024-05-10 02:28:27 INFO     evaluation data are prepared
2024-05-10 06:25:55 INFO     QA scores: {'exact_match': 90.96202013390491, 'f1': 96.4802648336491}
2024-05-10 06:25:55 INFO     PR scores: {'p@1': 1.0, 'p@2': 1.0, 'p@3': 1.0}
2024-05-10 06:26:05 INFO     PRQA scores: {'exact_match': 90.96202013390491, 'f1': 96.4802648336491}
{'loss': 0.6096, 'grad_norm': 22.540307998657227, 'learning_rate': 2.9199444948497625e-05, 'epoch': 0.0266851683834125}
{'loss': 0.213, 'grad_norm': 5.9184651374816895, 'learning_rate': 2.839888989699525e-05, 'epoch': 0.053370336766825}
{'loss': 0.182, 'grad_norm': 10.216676712036133, 'learning_rate': 2.7598334845492875e-05, 'epoch': 0.0800555051502375}
{'loss': 0.1698, 'grad_norm': 0.1278592199087143, 'learning_rate': 2.67977797939905e-05, 'epoch': 0.10674067353365}
{'loss': 0.1542, 'grad_norm': 4.428498268127441, 'learning_rate': 2.5997224742488124e-05, 'epoch': 0.1334258419170625}
{'loss': 0.1337, 'grad_norm': 3.795680046081543, 'learning_rate': 2.519666969098575e-05, 'epoch': 0.160111010300475}
{'loss': 0.1306, 'grad_norm': 7.032276630401611, 'learning_rate': 2.4396114639483373e-05, 'epoch': 0.18679617868388748}
{'loss': 0.1283, 'grad_norm': 3.2755274772644043, 'learning_rate': 2.3595559587980998e-05, 'epoch': 0.2134813470673}
{'loss': 0.1164, 'grad_norm': 0.9570974707603455, 'learning_rate': 2.2795004536478623e-05, 'epoch': 0.2401665154507125}
{'loss': 0.1114, 'grad_norm': 23.51786994934082, 'learning_rate': 2.1994449484976254e-05, 'epoch': 0.266851683834125}
{'loss': 0.1111, 'grad_norm': 0.32047930359840393, 'learning_rate': 2.119389443347388e-05, 'epoch': 0.2935368522175375}
{'loss': 0.0948, 'grad_norm': 0.3843052089214325, 'learning_rate': 2.0393339381971503e-05, 'epoch': 0.32022202060095}
{'loss': 0.1115, 'grad_norm': 0.09075472503900528, 'learning_rate': 1.9592784330469128e-05, 'epoch': 0.3469071889843625}
{'loss': 0.0984, 'grad_norm': 0.5653679966926575, 'learning_rate': 1.8792229278966753e-05, 'epoch': 0.37359235736777496}
{'loss': 0.0997, 'grad_norm': 30.507837295532227, 'learning_rate': 1.7991674227464377e-05, 'epoch': 0.40027752575118747}
{'loss': 0.0868, 'grad_norm': 14.16556167602539, 'learning_rate': 1.7191119175962002e-05, 'epoch': 0.4269626941346}
{'loss': 0.0799, 'grad_norm': 0.10233505070209503, 'learning_rate': 1.6390564124459626e-05, 'epoch': 0.4536478625180125}
{'loss': 0.0815, 'grad_norm': 6.650078296661377, 'learning_rate': 1.559000907295725e-05, 'epoch': 0.480333030901425}
{'loss': 0.0775, 'grad_norm': 3.6256651878356934, 'learning_rate': 1.4789454021454876e-05, 'epoch': 0.5070181992848375}
{'loss': 0.0698, 'grad_norm': 0.005954605061560869, 'learning_rate': 1.39888989699525e-05, 'epoch': 0.53370336766825}
{'loss': 0.0766, 'grad_norm': 2.441316843032837, 'learning_rate': 1.3188343918450125e-05, 'epoch': 0.5603885360516625}
{'loss': 0.0729, 'grad_norm': 0.1859198361635208, 'learning_rate': 1.238778886694775e-05, 'epoch': 0.587073704435075}
{'loss': 0.067, 'grad_norm': 13.880845069885254, 'learning_rate': 1.1587233815445374e-05, 'epoch': 0.6137588728184875}
{'loss': 0.0711, 'grad_norm': 7.583083629608154, 'learning_rate': 1.0786678763943e-05, 'epoch': 0.6404440412019}
{'loss': 0.0664, 'grad_norm': 1.1761256456375122, 'learning_rate': 9.986123712440627e-06, 'epoch': 0.6671292095853125}
{'loss': 0.0657, 'grad_norm': 0.009532146155834198, 'learning_rate': 9.185568660938252e-06, 'epoch': 0.693814377968725}
{'loss': 0.0581, 'grad_norm': 7.723790168762207, 'learning_rate': 8.385013609435876e-06, 'epoch': 0.7204995463521375}
{'loss': 0.0593, 'grad_norm': 0.0830797478556633, 'learning_rate': 7.584458557933501e-06, 'epoch': 0.7471847147355499}
{'loss': 0.0532, 'grad_norm': 18.881010055541992, 'learning_rate': 6.7839035064311256e-06, 'epoch': 0.7738698831189624}
{'loss': 0.0587, 'grad_norm': 0.08865047246217728, 'learning_rate': 5.98334845492875e-06, 'epoch': 0.8005550515023749}
{'loss': 0.0628, 'grad_norm': 0.035879891365766525, 'learning_rate': 5.182793403426376e-06, 'epoch': 0.8272402198857874}
{'loss': 0.0451, 'grad_norm': 10.148688316345215, 'learning_rate': 4.382238351924001e-06, 'epoch': 0.8539253882692}
{'loss': 0.0594, 'grad_norm': 0.35620149970054626, 'learning_rate': 3.581683300421626e-06, 'epoch': 0.8806105566526125}
{'loss': 0.0476, 'grad_norm': 0.011097196489572525, 'learning_rate': 2.781128248919251e-06, 'epoch': 0.907295725036025}
{'loss': 0.0539, 'grad_norm': 0.037458013743162155, 'learning_rate': 1.9805731974168755e-06, 'epoch': 0.9339808934194375}
{'loss': 0.0485, 'grad_norm': 1.2239383459091187, 'learning_rate': 1.1800181459145008e-06, 'epoch': 0.96066606180285}
{'loss': 0.0517, 'grad_norm': 0.023429667577147484, 'learning_rate': 3.794630944121257e-07, 'epoch': 0.9873512301862625}
{'eval_loss': 0.23175179958343506, 'eval_runtime': 3472.9362, 'eval_samples_per_second': 179.269, 'eval_steps_per_second': 0.7, 'epoch': 1.0}
{'train_runtime': 8532.7268, 'train_samples_per_second': 35.134, 'train_steps_per_second': 2.196, 'train_loss': 0.10390956975571748, 'epoch': 1.0}
Post-processing 166088 example predictions split into 1409362 features.
{
    "198": {
        "QA": {
            "exact_match": 90.96202013390491,
            "f1": 96.4802648336491
        },
        "PR": {
            "p@1": 1.0,
            "p@2": 1.0,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 90.96202013390491,
            "f1": 96.4802648336491
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3174471 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3174471 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
