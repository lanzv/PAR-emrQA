2024-05-12 09:33:55 INFO     ------------- Experiment: model BERTbase, frequency threshold 198 ---------------
2024-05-12 09:33:55 INFO     Contexts were splited into 360 paragraphs, which are 1.2080536912751678 paragraphs on average per one report. The overall paragraph average length (characters) is 4596.308333333333
2024-05-12 09:33:55 INFO     Contexts were splited into 47 paragraphs, which are 1.119047619047619 paragraphs on average per one report. The overall paragraph average length (characters) is 3829.723404255319
2024-05-12 09:33:56 INFO     Contexts were splited into 102 paragraphs, which are 1.186046511627907 paragraphs on average per one report. The overall paragraph average length (characters) is 4135.068627450981
2024-05-12 09:34:30 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-12 09:43:51 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-12 12:10:41 INFO     the model is trained
2024-05-12 12:31:34 INFO     evaluation data are prepared
2024-05-12 16:48:10 INFO     QA scores: {'exact_match': 89.40983093299937, 'f1': 95.02012425206594}
2024-05-12 16:48:10 INFO     PR scores: {'p@1': 0.990270218197582, 'p@2': 0.9990908434083137, 'p@3': 1.0}
2024-05-12 16:48:20 INFO     PRQA scores: {'exact_match': 88.83242618370984, 'f1': 94.55287577044605}
{'loss': 0.5782, 'grad_norm': 11.271140098571777, 'learning_rate': 2.9210609409535838e-05, 'epoch': 0.026313019682138724}
{'loss': 0.3174, 'grad_norm': 3.935054063796997, 'learning_rate': 2.8421218819071676e-05, 'epoch': 0.05262603936427745}
{'loss': 0.2581, 'grad_norm': 188.88185119628906, 'learning_rate': 2.7631828228607516e-05, 'epoch': 0.07893905904641617}
{'loss': 0.2415, 'grad_norm': 3.2752509117126465, 'learning_rate': 2.6842437638143354e-05, 'epoch': 0.1052520787285549}
{'loss': 0.2095, 'grad_norm': 7.143922328948975, 'learning_rate': 2.605304704767919e-05, 'epoch': 0.1315650984106936}
{'loss': 0.2071, 'grad_norm': 9.747355461120605, 'learning_rate': 2.526365645721503e-05, 'epoch': 0.15787811809283234}
{'loss': 0.1953, 'grad_norm': 11.09839916229248, 'learning_rate': 2.447426586675087e-05, 'epoch': 0.18419113777497106}
{'loss': 0.173, 'grad_norm': 2.8589894771575928, 'learning_rate': 2.3684875276286707e-05, 'epoch': 0.2105041574571098}
{'loss': 0.1697, 'grad_norm': 13.884324073791504, 'learning_rate': 2.2895484685822544e-05, 'epoch': 0.2368171771392485}
{'loss': 0.1592, 'grad_norm': 10.020477294921875, 'learning_rate': 2.210609409535838e-05, 'epoch': 0.2631301968213872}
{'loss': 0.1693, 'grad_norm': 26.750600814819336, 'learning_rate': 2.1316703504894222e-05, 'epoch': 0.28944321650352595}
{'loss': 0.1412, 'grad_norm': 5.965734004974365, 'learning_rate': 2.0527312914430063e-05, 'epoch': 0.3157562361856647}
{'loss': 0.1545, 'grad_norm': 0.6852478981018066, 'learning_rate': 1.97379223239659e-05, 'epoch': 0.3420692558678034}
{'loss': 0.1384, 'grad_norm': 11.798466682434082, 'learning_rate': 1.8948531733501738e-05, 'epoch': 0.36838227554994213}
{'loss': 0.1382, 'grad_norm': 0.3797066807746887, 'learning_rate': 1.8159141143037575e-05, 'epoch': 0.39469529523208086}
{'loss': 0.1352, 'grad_norm': 9.145583152770996, 'learning_rate': 1.7369750552573416e-05, 'epoch': 0.4210083149142196}
{'loss': 0.1245, 'grad_norm': 0.05725127086043358, 'learning_rate': 1.6580359962109254e-05, 'epoch': 0.44732133459635826}
{'loss': 0.1175, 'grad_norm': 5.236982822418213, 'learning_rate': 1.579096937164509e-05, 'epoch': 0.473634354278497}
{'loss': 0.1209, 'grad_norm': 2.6701090335845947, 'learning_rate': 1.5001578781180928e-05, 'epoch': 0.4999473739606357}
{'loss': 0.1162, 'grad_norm': 11.155623435974121, 'learning_rate': 1.4212188190716768e-05, 'epoch': 0.5262603936427744}
{'loss': 0.1074, 'grad_norm': 4.134284973144531, 'learning_rate': 1.3422797600252605e-05, 'epoch': 0.5525734133249132}
{'loss': 0.0924, 'grad_norm': 3.0599398612976074, 'learning_rate': 1.2633407009788444e-05, 'epoch': 0.5788864330070519}
{'loss': 0.1075, 'grad_norm': 15.299304008483887, 'learning_rate': 1.1844016419324281e-05, 'epoch': 0.6051994526891906}
{'loss': 0.0862, 'grad_norm': 0.8884164094924927, 'learning_rate': 1.105462582886012e-05, 'epoch': 0.6315124723713293}
{'loss': 0.1029, 'grad_norm': 0.7375923991203308, 'learning_rate': 1.0265235238395958e-05, 'epoch': 0.6578254920534681}
{'loss': 0.0798, 'grad_norm': 1.3568166494369507, 'learning_rate': 9.475844647931795e-06, 'epoch': 0.6841385117356068}
{'loss': 0.0873, 'grad_norm': 16.571157455444336, 'learning_rate': 8.686454057467636e-06, 'epoch': 0.7104515314177455}
{'loss': 0.089, 'grad_norm': 0.10376372933387756, 'learning_rate': 7.897063467003474e-06, 'epoch': 0.7367645510998843}
{'loss': 0.0829, 'grad_norm': 0.050337474793195724, 'learning_rate': 7.107672876539312e-06, 'epoch': 0.763077570782023}
{'loss': 0.075, 'grad_norm': 0.23627275228500366, 'learning_rate': 6.31828228607515e-06, 'epoch': 0.7893905904641617}
{'loss': 0.0802, 'grad_norm': 0.08220332115888596, 'learning_rate': 5.528891695610988e-06, 'epoch': 0.8157036101463004}
{'loss': 0.0693, 'grad_norm': 0.01454602275043726, 'learning_rate': 4.739501105146827e-06, 'epoch': 0.8420166298284392}
{'loss': 0.0739, 'grad_norm': 0.012646625749766827, 'learning_rate': 3.950110514682665e-06, 'epoch': 0.8683296495105778}
{'loss': 0.0705, 'grad_norm': 7.278143405914307, 'learning_rate': 3.1607199242185035e-06, 'epoch': 0.8946426691927165}
{'loss': 0.0591, 'grad_norm': 0.03163937106728554, 'learning_rate': 2.3713293337543418e-06, 'epoch': 0.9209556888748552}
{'loss': 0.061, 'grad_norm': 8.404969215393066, 'learning_rate': 1.58193874329018e-06, 'epoch': 0.947268708556994}
{'loss': 0.0658, 'grad_norm': 0.13114893436431885, 'learning_rate': 7.925481528260183e-07, 'epoch': 0.9735817282391327}
{'loss': 0.066, 'grad_norm': 0.046690911054611206, 'learning_rate': 3.1575623618566468e-09, 'epoch': 0.9998947479212714}
{'eval_loss': 0.2590296268463135, 'eval_runtime': 3715.2231, 'eval_samples_per_second': 180.332, 'eval_steps_per_second': 0.705, 'epoch': 1.0}
{'train_runtime': 8808.2093, 'train_samples_per_second': 34.516, 'train_steps_per_second': 2.157, 'train_loss': 0.14002716108731578, 'epoch': 1.0}
Post-processing 238640 example predictions split into 1524121 features.
{
    "198": {
        "QA": {
            "exact_match": 89.40983093299937,
            "f1": 95.02012425206594
        },
        "PR": {
            "p@1": 0.990270218197582,
            "p@2": 0.9990908434083137,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.83242618370984,
            "f1": 94.55287577044605
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 717541 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 717541 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
