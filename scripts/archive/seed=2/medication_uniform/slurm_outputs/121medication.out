2024-05-11 12:22:57 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 121 ---------------
2024-05-11 12:22:57 INFO     Contexts were splited into 544 paragraphs, which are 2.9726775956284155 paragraphs on average per one report. The overall paragraph average length (characters) is 2211.9025735294117
2024-05-11 12:22:57 INFO     Contexts were splited into 81 paragraphs, which are 3.1153846153846154 paragraphs on average per one report. The overall paragraph average length (characters) is 2235.9753086419755
2024-05-11 12:22:57 INFO     Contexts were splited into 149 paragraphs, which are 2.811320754716981 paragraphs on average per one report. The overall paragraph average length (characters) is 2275.046979865772
2024-05-11 12:23:05 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-11 12:25:59 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-11 13:22:04 INFO     the model is trained
2024-05-11 13:27:32 INFO     evaluation data are prepared
2024-05-11 14:33:51 INFO     QA scores: {'exact_match': 30.681671749495298, 'f1': 73.30930345750053}
2024-05-11 14:33:51 INFO     PR scores: {'p@1': 0.9457067995361024, 'p@2': 0.9957261286027232, 'p@3': 0.9998496628151712}
2024-05-11 14:33:54 INFO     PRQA scores: {'exact_match': 30.05240324728319, 'f1': 71.16649698580369}
{'loss': 1.2655, 'grad_norm': 8.889798164367676, 'learning_rate': 2.8560046078525487e-05, 'epoch': 0.047998464049150424}
{'loss': 0.7925, 'grad_norm': 3.927589178085327, 'learning_rate': 2.7120092157050974e-05, 'epoch': 0.09599692809830085}
{'loss': 0.6921, 'grad_norm': 3.2261414527893066, 'learning_rate': 2.5680138235576463e-05, 'epoch': 0.14399539214745127}
{'loss': 0.6347, 'grad_norm': 12.592792510986328, 'learning_rate': 2.424018431410195e-05, 'epoch': 0.1919938561966017}
{'loss': 0.5828, 'grad_norm': 6.733815670013428, 'learning_rate': 2.2800230392627436e-05, 'epoch': 0.23999232024575212}
{'loss': 0.4994, 'grad_norm': 14.55152416229248, 'learning_rate': 2.1360276471152923e-05, 'epoch': 0.28799078429490255}
{'loss': 0.4604, 'grad_norm': 8.807075500488281, 'learning_rate': 1.9920322549678412e-05, 'epoch': 0.33598924834405297}
{'loss': 0.4227, 'grad_norm': 14.297527313232422, 'learning_rate': 1.84803686282039e-05, 'epoch': 0.3839877123932034}
{'loss': 0.4143, 'grad_norm': 6.582155704498291, 'learning_rate': 1.7040414706729385e-05, 'epoch': 0.4319861764423538}
{'loss': 0.3592, 'grad_norm': 2.9562828540802, 'learning_rate': 1.5600460785254872e-05, 'epoch': 0.47998464049150424}
{'loss': 0.3414, 'grad_norm': 6.065406799316406, 'learning_rate': 1.4160506863780358e-05, 'epoch': 0.5279831045406547}
{'loss': 0.3141, 'grad_norm': 11.236849784851074, 'learning_rate': 1.2720552942305846e-05, 'epoch': 0.5759815685898051}
{'loss': 0.289, 'grad_norm': 0.8055946230888367, 'learning_rate': 1.1280599020831333e-05, 'epoch': 0.6239800326389555}
{'loss': 0.2794, 'grad_norm': 13.885642051696777, 'learning_rate': 9.84064509935682e-06, 'epoch': 0.6719784966881059}
{'loss': 0.253, 'grad_norm': 15.037457466125488, 'learning_rate': 8.400691177882307e-06, 'epoch': 0.7199769607372564}
{'loss': 0.238, 'grad_norm': 9.574186325073242, 'learning_rate': 6.9607372564077944e-06, 'epoch': 0.7679754247864068}
{'loss': 0.2275, 'grad_norm': 11.194921493530273, 'learning_rate': 5.520783334933282e-06, 'epoch': 0.8159738888355572}
{'loss': 0.2195, 'grad_norm': 0.797494113445282, 'learning_rate': 4.080829413458769e-06, 'epoch': 0.8639723528847076}
{'loss': 0.2158, 'grad_norm': 12.691303253173828, 'learning_rate': 2.6408754919842566e-06, 'epoch': 0.9119708169338581}
{'loss': 0.1982, 'grad_norm': 2.231307029724121, 'learning_rate': 1.2009215705097437e-06, 'epoch': 0.9599692809830085}
{'eval_loss': 1.2246811389923096, 'eval_runtime': 574.6467, 'eval_samples_per_second': 180.182, 'eval_steps_per_second': 0.705, 'epoch': 1.0}
{'train_runtime': 3364.1304, 'train_samples_per_second': 49.543, 'train_steps_per_second': 3.096, 'train_loss': 0.42582849043166554, 'epoch': 1.0}
Post-processing 145864 example predictions split into 389932 features.
{
    "121": {
        "QA": {
            "exact_match": 30.681671749495298,
            "f1": 73.30930345750053
        },
        "PR": {
            "p@1": 0.9457067995361024,
            "p@2": 0.9957261286027232,
            "p@3": 0.9998496628151712
        },
        "PRQA": {
            "exact_match": 30.05240324728319,
            "f1": 71.16649698580369
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 713202 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 713202 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
