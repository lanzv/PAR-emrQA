2024-05-12 02:35:21 INFO     ------------- Experiment: model BERTbase, frequency threshold 134 ---------------
2024-05-12 02:35:21 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-12 02:35:21 INFO     Contexts were splited into 1585 paragraphs, which are 5.318791946308725 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 1064.9192429022082
2024-05-12 02:35:21 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-12 02:35:21 INFO     Contexts were splited into 204 paragraphs, which are 4.857142857142857 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 900.3333333333334
2024-05-12 02:35:22 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-12 02:35:22 INFO     Contexts were splited into 428 paragraphs, which are 4.976744186046512 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 1005.4649532710281
2024-05-12 02:36:00 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-12 02:43:45 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-12 04:54:34 INFO     the model is trained
2024-05-12 05:19:50 INFO     evaluation data are prepared
2024-05-12 10:59:18 INFO     QA scores: {'exact_match': 89.32132363566302, 'f1': 95.08979430496541}
2024-05-12 10:59:19 INFO     PR scores: {'p@1': 0.9870430133423246, 'p@2': 0.9974832618852656, 'p@3': 0.9995484321564472}
2024-05-12 10:59:28 INFO     PRQA scores: {'exact_match': 88.37965415924089, 'f1': 94.3655248990242}
{'loss': 0.626, 'grad_norm': 7.164421081542969, 'learning_rate': 2.9119821617181083e-05, 'epoch': 0.029339279427297266}
{'loss': 0.3126, 'grad_norm': 11.053013801574707, 'learning_rate': 2.8239643234362166e-05, 'epoch': 0.05867855885459453}
{'loss': 0.2668, 'grad_norm': 30.114654541015625, 'learning_rate': 2.7359464851543248e-05, 'epoch': 0.0880178382818918}
{'loss': 0.2345, 'grad_norm': 5.781074523925781, 'learning_rate': 2.6479286468724327e-05, 'epoch': 0.11735711770918907}
{'loss': 0.2047, 'grad_norm': 1.1895320415496826, 'learning_rate': 2.5599108085905413e-05, 'epoch': 0.14669639713648633}
{'loss': 0.2233, 'grad_norm': 11.763097763061523, 'learning_rate': 2.4718929703086492e-05, 'epoch': 0.1760356765637836}
{'loss': 0.1885, 'grad_norm': 0.2033368945121765, 'learning_rate': 2.3838751320267574e-05, 'epoch': 0.20537495599108085}
{'loss': 0.1898, 'grad_norm': 8.547589302062988, 'learning_rate': 2.2958572937448657e-05, 'epoch': 0.23471423541837813}
{'loss': 0.1612, 'grad_norm': 13.748458862304688, 'learning_rate': 2.207839455462974e-05, 'epoch': 0.2640535148456754}
{'loss': 0.1546, 'grad_norm': 9.196328163146973, 'learning_rate': 2.119821617181082e-05, 'epoch': 0.29339279427297266}
{'loss': 0.142, 'grad_norm': 23.550065994262695, 'learning_rate': 2.0318037788991904e-05, 'epoch': 0.3227320737002699}
{'loss': 0.1426, 'grad_norm': 1.2737153768539429, 'learning_rate': 1.9437859406172983e-05, 'epoch': 0.3520713531275672}
{'loss': 0.1325, 'grad_norm': 0.13075701892375946, 'learning_rate': 1.855768102335407e-05, 'epoch': 0.38141063255486446}
{'loss': 0.1185, 'grad_norm': 5.1979451179504395, 'learning_rate': 1.7677502640535148e-05, 'epoch': 0.4107499119821617}
{'loss': 0.148, 'grad_norm': 12.68179702758789, 'learning_rate': 1.679732425771623e-05, 'epoch': 0.44008919140945896}
{'loss': 0.1361, 'grad_norm': 0.3834541141986847, 'learning_rate': 1.5917145874897313e-05, 'epoch': 0.46942847083675626}
{'loss': 0.118, 'grad_norm': 2.503206968307495, 'learning_rate': 1.5036967492078395e-05, 'epoch': 0.4987677502640535}
{'loss': 0.1118, 'grad_norm': 31.663915634155273, 'learning_rate': 1.4156789109259477e-05, 'epoch': 0.5281070296913508}
{'loss': 0.1, 'grad_norm': 16.474729537963867, 'learning_rate': 1.3276610726440558e-05, 'epoch': 0.557446309118648}
{'loss': 0.1126, 'grad_norm': 15.312246322631836, 'learning_rate': 1.239643234362164e-05, 'epoch': 0.5867855885459453}
{'loss': 0.0879, 'grad_norm': 7.3213372230529785, 'learning_rate': 1.1516253960802723e-05, 'epoch': 0.6161248679732426}
{'loss': 0.0923, 'grad_norm': 0.03732278198003769, 'learning_rate': 1.0636075577983804e-05, 'epoch': 0.6454641474005398}
{'loss': 0.0967, 'grad_norm': 0.11407690495252609, 'learning_rate': 9.755897195164886e-06, 'epoch': 0.6748034268278371}
{'loss': 0.0847, 'grad_norm': 0.182008296251297, 'learning_rate': 8.875718812345969e-06, 'epoch': 0.7041427062551344}
{'loss': 0.0868, 'grad_norm': 0.4590098559856415, 'learning_rate': 7.995540429527051e-06, 'epoch': 0.7334819856824316}
{'loss': 0.0799, 'grad_norm': 4.240596771240234, 'learning_rate': 7.1153620467081325e-06, 'epoch': 0.7628212651097289}
{'loss': 0.0817, 'grad_norm': 3.7814109325408936, 'learning_rate': 6.235183663889215e-06, 'epoch': 0.7921605445370262}
{'loss': 0.0697, 'grad_norm': 0.27124452590942383, 'learning_rate': 5.3550052810702965e-06, 'epoch': 0.8214998239643234}
{'loss': 0.0702, 'grad_norm': 0.07447893172502518, 'learning_rate': 4.474826898251379e-06, 'epoch': 0.8508391033916207}
{'loss': 0.0766, 'grad_norm': 10.66547679901123, 'learning_rate': 3.594648515432461e-06, 'epoch': 0.8801783828189179}
{'loss': 0.0769, 'grad_norm': 0.5090261697769165, 'learning_rate': 2.714470132613543e-06, 'epoch': 0.9095176622462152}
{'loss': 0.0609, 'grad_norm': 0.05511222407221794, 'learning_rate': 1.834291749794625e-06, 'epoch': 0.9388569416735125}
{'loss': 0.0617, 'grad_norm': 2.3177695274353027, 'learning_rate': 9.54113366975707e-07, 'epoch': 0.9681962211008097}
{'loss': 0.0563, 'grad_norm': 4.0083723068237305, 'learning_rate': 7.393498415678911e-08, 'epoch': 0.997535500528107}
{'eval_loss': 0.29850709438323975, 'eval_runtime': 3323.4363, 'eval_samples_per_second': 183.233, 'eval_steps_per_second': 0.716, 'epoch': 1.0}
{'train_runtime': 7848.4107, 'train_samples_per_second': 34.741, 'train_steps_per_second': 2.171, 'train_loss': 0.14404845323071291, 'epoch': 1.0}
Post-processing 897369 example predictions split into 2047141 features.
{
    "134": {
        "QA": {
            "exact_match": 89.32132363566302,
            "f1": 95.08979430496541
        },
        "PR": {
            "p@1": 0.9870430133423246,
            "p@2": 0.9974832618852656,
            "p@3": 0.9995484321564472
        },
        "PRQA": {
            "exact_match": 88.37965415924089,
            "f1": 94.3655248990242
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 2752102 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 2752102 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
