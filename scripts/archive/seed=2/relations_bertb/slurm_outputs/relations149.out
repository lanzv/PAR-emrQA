2024-05-12 02:08:03 INFO     ------------- Experiment: model BERTbase, frequency threshold 149 ---------------
2024-05-12 02:08:03 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-12 02:08:03 INFO     Contexts were splited into 864 paragraphs, which are 2.8993288590604025 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 149. The overall paragraph average length (characters) is 1953.5844907407406
2024-05-12 02:08:04 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-12 02:08:04 INFO     Contexts were splited into 127 paragraphs, which are 3.0238095238095237 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 149. The overall paragraph average length (characters) is 1446.2047244094488
2024-05-12 02:08:04 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-12 02:08:04 INFO     Contexts were splited into 252 paragraphs, which are 2.9302325581395348 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 149. The overall paragraph average length (characters) is 1707.6944444444443
2024-05-12 02:08:42 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-12 02:18:29 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-12 05:03:17 INFO     the model is trained
2024-05-12 05:26:43 INFO     evaluation data are prepared
2024-05-12 10:26:41 INFO     QA scores: {'exact_match': 89.12624632724821, 'f1': 94.77166810294246}
2024-05-12 10:26:41 INFO     PR scores: {'p@1': 0.9903003227204855, 'p@2': 0.998452627522759, 'p@3': 1.0}
2024-05-12 10:26:51 INFO     PRQA scores: {'exact_match': 88.525962140552, 'f1': 94.24933846235416}
{'loss': 0.6053, 'grad_norm': 17.902267456054688, 'learning_rate': 2.929712759477063e-05, 'epoch': 0.023429080174312358}
{'loss': 0.2694, 'grad_norm': 2.336984157562256, 'learning_rate': 2.859425518954126e-05, 'epoch': 0.046858160348624715}
{'loss': 0.2393, 'grad_norm': 7.897967338562012, 'learning_rate': 2.7891382784311888e-05, 'epoch': 0.07028724052293707}
{'loss': 0.2233, 'grad_norm': 3.90293288230896, 'learning_rate': 2.7188510379082517e-05, 'epoch': 0.09371632069724943}
{'loss': 0.2201, 'grad_norm': 0.8055214881896973, 'learning_rate': 2.6485637973853147e-05, 'epoch': 0.11714540087156178}
{'loss': 0.1858, 'grad_norm': 1.6469988822937012, 'learning_rate': 2.5782765568623776e-05, 'epoch': 0.14057448104587414}
{'loss': 0.1763, 'grad_norm': 32.64987564086914, 'learning_rate': 2.5079893163394408e-05, 'epoch': 0.1640035612201865}
{'loss': 0.1864, 'grad_norm': 0.05499500781297684, 'learning_rate': 2.4377020758165034e-05, 'epoch': 0.18743264139449886}
{'loss': 0.1627, 'grad_norm': 6.791793346405029, 'learning_rate': 2.3674148352935663e-05, 'epoch': 0.21086172156881122}
{'loss': 0.1518, 'grad_norm': 11.567459106445312, 'learning_rate': 2.2971275947706292e-05, 'epoch': 0.23429080174312356}
{'loss': 0.1514, 'grad_norm': 15.662558555603027, 'learning_rate': 2.2268403542476925e-05, 'epoch': 0.25771988191743594}
{'loss': 0.1513, 'grad_norm': 9.02907943725586, 'learning_rate': 2.156553113724755e-05, 'epoch': 0.2811489620917483}
{'loss': 0.1527, 'grad_norm': 12.104422569274902, 'learning_rate': 2.086265873201818e-05, 'epoch': 0.3045780422660606}
{'loss': 0.1431, 'grad_norm': 16.877408981323242, 'learning_rate': 2.015978632678881e-05, 'epoch': 0.328007122440373}
{'loss': 0.1308, 'grad_norm': 1.6286911964416504, 'learning_rate': 1.945691392155944e-05, 'epoch': 0.35143620261468533}
{'loss': 0.1187, 'grad_norm': 14.26732063293457, 'learning_rate': 1.875404151633007e-05, 'epoch': 0.3748652827889977}
{'loss': 0.1224, 'grad_norm': 15.414690971374512, 'learning_rate': 1.8051169111100696e-05, 'epoch': 0.39829436296331006}
{'loss': 0.1208, 'grad_norm': 1.2503920793533325, 'learning_rate': 1.7348296705871326e-05, 'epoch': 0.42172344313762244}
{'loss': 0.1175, 'grad_norm': 22.862735748291016, 'learning_rate': 1.6645424300641958e-05, 'epoch': 0.4451525233119348}
{'loss': 0.1022, 'grad_norm': 0.7030718326568604, 'learning_rate': 1.5942551895412587e-05, 'epoch': 0.4685816034862471}
{'loss': 0.1116, 'grad_norm': 6.683488845825195, 'learning_rate': 1.5239679490183217e-05, 'epoch': 0.4920106836605595}
{'loss': 0.0977, 'grad_norm': 0.05502895265817642, 'learning_rate': 1.4536807084953846e-05, 'epoch': 0.5154397638348719}
{'loss': 0.1029, 'grad_norm': 7.360721588134766, 'learning_rate': 1.3833934679724473e-05, 'epoch': 0.5388688440091842}
{'loss': 0.1126, 'grad_norm': 3.9381468296051025, 'learning_rate': 1.3131062274495104e-05, 'epoch': 0.5622979241834966}
{'loss': 0.0889, 'grad_norm': 0.0046828147023916245, 'learning_rate': 1.2428189869265733e-05, 'epoch': 0.5857270043578089}
{'loss': 0.089, 'grad_norm': 12.636597633361816, 'learning_rate': 1.1725317464036362e-05, 'epoch': 0.6091560845321212}
{'loss': 0.0814, 'grad_norm': 0.2397768795490265, 'learning_rate': 1.1022445058806991e-05, 'epoch': 0.6325851647064337}
{'loss': 0.0958, 'grad_norm': 13.75024127960205, 'learning_rate': 1.031957265357762e-05, 'epoch': 0.656014244880746}
{'loss': 0.0923, 'grad_norm': 0.03040461242198944, 'learning_rate': 9.61670024834825e-06, 'epoch': 0.6794433250550583}
{'loss': 0.0801, 'grad_norm': 5.818768501281738, 'learning_rate': 8.913827843118879e-06, 'epoch': 0.7028724052293707}
{'loss': 0.073, 'grad_norm': 2.4217824935913086, 'learning_rate': 8.210955437889508e-06, 'epoch': 0.726301485403683}
{'loss': 0.0695, 'grad_norm': 0.08249444514513016, 'learning_rate': 7.508083032660138e-06, 'epoch': 0.7497305655779954}
{'loss': 0.0671, 'grad_norm': 1.6479111909866333, 'learning_rate': 6.8052106274307664e-06, 'epoch': 0.7731596457523078}
{'loss': 0.0738, 'grad_norm': 0.0884392186999321, 'learning_rate': 6.1023382222013964e-06, 'epoch': 0.7965887259266201}
{'loss': 0.0712, 'grad_norm': 0.13701681792736053, 'learning_rate': 5.399465816972026e-06, 'epoch': 0.8200178061009324}
{'loss': 0.0689, 'grad_norm': 0.09807304292917252, 'learning_rate': 4.696593411742655e-06, 'epoch': 0.8434468862752449}
{'loss': 0.0758, 'grad_norm': 0.021243873983621597, 'learning_rate': 3.993721006513284e-06, 'epoch': 0.8668759664495572}
{'loss': 0.0585, 'grad_norm': 0.032637834548950195, 'learning_rate': 3.290848601283914e-06, 'epoch': 0.8903050466238696}
{'loss': 0.0719, 'grad_norm': 0.02785639464855194, 'learning_rate': 2.587976196054543e-06, 'epoch': 0.9137341267981819}
{'loss': 0.0601, 'grad_norm': 0.20553173124790192, 'learning_rate': 1.885103790825172e-06, 'epoch': 0.9371632069724942}
{'loss': 0.0561, 'grad_norm': 0.2195248007774353, 'learning_rate': 1.1822313855958014e-06, 'epoch': 0.9605922871468067}
{'loss': 0.0624, 'grad_norm': 0.23334039747714996, 'learning_rate': 4.793589803664309e-07, 'epoch': 0.984021367321119}
{'eval_loss': 0.24852068722248077, 'eval_runtime': 4087.344, 'eval_samples_per_second': 178.182, 'eval_steps_per_second': 0.696, 'epoch': 1.0}
{'train_runtime': 9887.424, 'train_samples_per_second': 34.534, 'train_steps_per_second': 2.158, 'train_loss': 0.1296842915680788, 'epoch': 1.0}
Post-processing 492433 example predictions split into 1778982 features.
{
    "149": {
        "QA": {
            "exact_match": 89.12624632724821,
            "f1": 94.77166810294246
        },
        "PR": {
            "p@1": 0.9903003227204855,
            "p@2": 0.998452627522759,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.525962140552,
            "f1": 94.24933846235416
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3670166 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3670166 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
