2024-05-12 01:22:20 INFO     ------------- Experiment: model BERTbase, frequency threshold 190 ---------------
2024-05-12 01:22:20 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-12 01:22:20 INFO     Contexts were splited into 495 paragraphs, which are 1.6610738255033557 paragraphs on average per one report. There are 1 unique topics with frequency threshold (greater or equal) 190. The overall paragraph average length (characters) is 3409.8929292929292
2024-05-12 01:22:20 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-12 01:22:20 INFO     Contexts were splited into 69 paragraphs, which are 1.6428571428571428 paragraphs on average per one report. There are 1 unique topics with frequency threshold (greater or equal) 190. The overall paragraph average length (characters) is 2661.855072463768
2024-05-12 01:22:21 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-12 01:22:21 INFO     Contexts were splited into 141 paragraphs, which are 1.6395348837209303 paragraphs on average per one report. There are 1 unique topics with frequency threshold (greater or equal) 190. The overall paragraph average length (characters) is 3052.049645390071
2024-05-12 01:23:00 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-12 01:33:06 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-12 04:16:56 INFO     the model is trained
2024-05-12 04:38:45 INFO     evaluation data are prepared
2024-05-12 09:14:01 INFO     QA scores: {'exact_match': 89.0570059245701, 'f1': 94.81665378152363}
2024-05-12 09:14:01 INFO     PR scores: {'p@1': 0.9979167670150764, 'p@2': 1.0, 'p@3': 1.0}
2024-05-12 09:14:12 INFO     PRQA scores: {'exact_match': 88.87698087760705, 'f1': 94.65478836686412}
{'loss': 0.5661, 'grad_norm': 9.497917175292969, 'learning_rate': 2.930017728842027e-05, 'epoch': 0.023327423719324437}
{'loss': 0.2742, 'grad_norm': 5.4550628662109375, 'learning_rate': 2.8600354576840536e-05, 'epoch': 0.04665484743864887}
{'loss': 0.2475, 'grad_norm': 5.5066142082214355, 'learning_rate': 2.79005318652608e-05, 'epoch': 0.06998227115797331}
{'loss': 0.2236, 'grad_norm': 17.166013717651367, 'learning_rate': 2.7200709153681067e-05, 'epoch': 0.09330969487729775}
{'loss': 0.2166, 'grad_norm': 6.872490882873535, 'learning_rate': 2.6500886442101336e-05, 'epoch': 0.1166371185966222}
{'loss': 0.2028, 'grad_norm': 2.7066450119018555, 'learning_rate': 2.5801063730521605e-05, 'epoch': 0.13996454231594663}
{'loss': 0.1775, 'grad_norm': 0.5257627367973328, 'learning_rate': 2.5101241018941867e-05, 'epoch': 0.16329196603527107}
{'loss': 0.1764, 'grad_norm': 12.30698299407959, 'learning_rate': 2.4401418307362137e-05, 'epoch': 0.1866193897545955}
{'loss': 0.169, 'grad_norm': 2.306760549545288, 'learning_rate': 2.3701595595782402e-05, 'epoch': 0.20994681347391994}
{'loss': 0.1586, 'grad_norm': 9.694023132324219, 'learning_rate': 2.300177288420267e-05, 'epoch': 0.2332742371932444}
{'loss': 0.1551, 'grad_norm': 22.24997329711914, 'learning_rate': 2.2301950172622934e-05, 'epoch': 0.2566016609125688}
{'loss': 0.1555, 'grad_norm': 9.87199592590332, 'learning_rate': 2.1602127461043203e-05, 'epoch': 0.27992908463189325}
{'loss': 0.1353, 'grad_norm': 12.775644302368164, 'learning_rate': 2.0902304749463472e-05, 'epoch': 0.3032565083512177}
{'loss': 0.141, 'grad_norm': 2.7920639514923096, 'learning_rate': 2.0202482037883738e-05, 'epoch': 0.32658393207054215}
{'loss': 0.1414, 'grad_norm': 0.06836871057748795, 'learning_rate': 1.9502659326304003e-05, 'epoch': 0.34991135578986654}
{'loss': 0.1192, 'grad_norm': 0.14111199975013733, 'learning_rate': 1.880283661472427e-05, 'epoch': 0.373238779509191}
{'loss': 0.1287, 'grad_norm': 0.21197134256362915, 'learning_rate': 1.8103013903144538e-05, 'epoch': 0.39656620322851543}
{'loss': 0.1281, 'grad_norm': 0.1966300904750824, 'learning_rate': 1.7403191191564807e-05, 'epoch': 0.4198936269478399}
{'loss': 0.1148, 'grad_norm': 0.3061661422252655, 'learning_rate': 1.670336847998507e-05, 'epoch': 0.44322105066716433}
{'loss': 0.1104, 'grad_norm': 0.19411373138427734, 'learning_rate': 1.600354576840534e-05, 'epoch': 0.4665484743864888}
{'loss': 0.1145, 'grad_norm': 7.344066619873047, 'learning_rate': 1.5303723056825604e-05, 'epoch': 0.48987589810581317}
{'loss': 0.0974, 'grad_norm': 0.09397426247596741, 'learning_rate': 1.4603900345245872e-05, 'epoch': 0.5132033218251376}
{'loss': 0.1048, 'grad_norm': 3.0812649726867676, 'learning_rate': 1.3904077633666139e-05, 'epoch': 0.5365307455444621}
{'loss': 0.1, 'grad_norm': 3.9281885623931885, 'learning_rate': 1.3204254922086405e-05, 'epoch': 0.5598581692637865}
{'loss': 0.0994, 'grad_norm': 34.72166442871094, 'learning_rate': 1.2504432210506672e-05, 'epoch': 0.5831855929831109}
{'loss': 0.0943, 'grad_norm': 21.517011642456055, 'learning_rate': 1.1804609498926938e-05, 'epoch': 0.6065130167024354}
{'loss': 0.0897, 'grad_norm': 0.032027218490839005, 'learning_rate': 1.1104786787347207e-05, 'epoch': 0.6298404404217598}
{'loss': 0.0845, 'grad_norm': 0.025638621300458908, 'learning_rate': 1.0404964075767473e-05, 'epoch': 0.6531678641410843}
{'loss': 0.0816, 'grad_norm': 0.9884087443351746, 'learning_rate': 9.70514136418774e-06, 'epoch': 0.6764952878604087}
{'loss': 0.0895, 'grad_norm': 0.02624547854065895, 'learning_rate': 9.005318652608006e-06, 'epoch': 0.6998227115797331}
{'loss': 0.079, 'grad_norm': 0.04053947329521179, 'learning_rate': 8.305495941028273e-06, 'epoch': 0.7231501352990576}
{'loss': 0.0847, 'grad_norm': 0.2306203693151474, 'learning_rate': 7.60567322944854e-06, 'epoch': 0.746477559018382}
{'loss': 0.0732, 'grad_norm': 0.039302777498960495, 'learning_rate': 6.905850517868807e-06, 'epoch': 0.7698049827377065}
{'loss': 0.078, 'grad_norm': 10.946224212646484, 'learning_rate': 6.2060278062890735e-06, 'epoch': 0.7931324064570309}
{'loss': 0.0783, 'grad_norm': 0.32543328404426575, 'learning_rate': 5.506205094709341e-06, 'epoch': 0.8164598301763554}
{'loss': 0.0716, 'grad_norm': 24.763221740722656, 'learning_rate': 4.8063823831296075e-06, 'epoch': 0.8397872538956798}
{'loss': 0.0695, 'grad_norm': 44.560997009277344, 'learning_rate': 4.106559671549874e-06, 'epoch': 0.8631146776150042}
{'loss': 0.0747, 'grad_norm': 1.6200658082962036, 'learning_rate': 3.406736959970141e-06, 'epoch': 0.8864421013343287}
{'loss': 0.0679, 'grad_norm': 1.0417296886444092, 'learning_rate': 2.7069142483904075e-06, 'epoch': 0.909769525053653}
{'loss': 0.0601, 'grad_norm': 0.06359177827835083, 'learning_rate': 2.007091536810675e-06, 'epoch': 0.9330969487729776}
{'loss': 0.0728, 'grad_norm': 0.2006617784500122, 'learning_rate': 1.3072688252309415e-06, 'epoch': 0.9564243724923019}
{'loss': 0.0635, 'grad_norm': 0.11428403854370117, 'learning_rate': 6.074461136512083e-07, 'epoch': 0.9797517962116263}
{'eval_loss': 0.2545750141143799, 'eval_runtime': 4038.2795, 'eval_samples_per_second': 179.283, 'eval_steps_per_second': 0.701, 'epoch': 1.0}
{'train_runtime': 9829.344, 'train_samples_per_second': 34.889, 'train_steps_per_second': 2.181, 'train_loss': 0.13105907993685056, 'epoch': 1.0}
Post-processing 290387 example predictions split into 1625210 features.
{
    "190": {
        "QA": {
            "exact_match": 89.0570059245701,
            "f1": 94.81665378152363
        },
        "PR": {
            "p@1": 0.9979167670150764,
            "p@2": 1.0,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.87698087760705,
            "f1": 94.65478836686412
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3231331 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3231331 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
