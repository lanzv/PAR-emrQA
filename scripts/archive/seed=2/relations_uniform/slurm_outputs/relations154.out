2024-05-11 23:46:17 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 154 ---------------
2024-05-11 23:46:17 INFO     Contexts were splited into 716 paragraphs, which are 2.402684563758389 paragraphs on average per one report. The overall paragraph average length (characters) is 2310.9930167597763
2024-05-11 23:46:17 INFO     Contexts were splited into 79 paragraphs, which are 1.880952380952381 paragraphs on average per one report. The overall paragraph average length (characters) is 2278.4430379746836
2024-05-11 23:46:18 INFO     Contexts were splited into 188 paragraphs, which are 2.186046511627907 paragraphs on average per one report. The overall paragraph average length (characters) is 2243.494680851064
2024-05-11 23:46:46 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-11 23:53:06 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-12 01:22:06 INFO     the model is trained
2024-05-12 01:43:29 INFO     evaluation data are prepared
2024-05-12 05:42:09 INFO     QA scores: {'exact_match': 92.24808535234334, 'f1': 97.34976769609088}
2024-05-12 05:42:10 INFO     PR scores: {'p@1': 0.9875307066133616, 'p@2': 0.9984104811906941, 'p@3': 0.9998013101488368}
2024-05-12 05:42:20 INFO     PRQA scores: {'exact_match': 91.35699147439911, 'f1': 96.54700300831972}
{'loss': 0.6163, 'grad_norm': 8.134420394897461, 'learning_rate': 2.86633398681162e-05, 'epoch': 0.044555337729459986}
{'loss': 0.2416, 'grad_norm': 16.309059143066406, 'learning_rate': 2.7326679736232404e-05, 'epoch': 0.08911067545891997}
{'loss': 0.1987, 'grad_norm': 14.075471878051758, 'learning_rate': 2.59900196043486e-05, 'epoch': 0.13366601318837998}
{'loss': 0.1842, 'grad_norm': 2.243791341781616, 'learning_rate': 2.46533594724648e-05, 'epoch': 0.17822135091783994}
{'loss': 0.1477, 'grad_norm': 5.767965316772461, 'learning_rate': 2.3316699340581e-05, 'epoch': 0.22277668864729994}
{'loss': 0.142, 'grad_norm': 0.6319850087165833, 'learning_rate': 2.1980039208697205e-05, 'epoch': 0.26733202637675996}
{'loss': 0.1223, 'grad_norm': 0.07342271506786346, 'learning_rate': 2.0643379076813402e-05, 'epoch': 0.3118873641062199}
{'loss': 0.1277, 'grad_norm': 7.641776084899902, 'learning_rate': 1.9306718944929602e-05, 'epoch': 0.3564427018356799}
{'loss': 0.1106, 'grad_norm': 5.502670764923096, 'learning_rate': 1.7970058813045802e-05, 'epoch': 0.4009980395651399}
{'loss': 0.1136, 'grad_norm': 0.22855854034423828, 'learning_rate': 1.6633398681162006e-05, 'epoch': 0.4455533772945999}
{'loss': 0.1025, 'grad_norm': 1.0409095287322998, 'learning_rate': 1.5296738549278206e-05, 'epoch': 0.4901087150240599}
{'loss': 0.0953, 'grad_norm': 0.1881696730852127, 'learning_rate': 1.3960078417394404e-05, 'epoch': 0.5346640527535199}
{'loss': 0.0987, 'grad_norm': 7.358700752258301, 'learning_rate': 1.2623418285510604e-05, 'epoch': 0.5792193904829799}
{'loss': 0.0747, 'grad_norm': 2.583115577697754, 'learning_rate': 1.1286758153626805e-05, 'epoch': 0.6237747282124398}
{'loss': 0.0846, 'grad_norm': 0.4179043769836426, 'learning_rate': 9.950098021743005e-06, 'epoch': 0.6683300659418998}
{'loss': 0.0795, 'grad_norm': 0.06394573301076889, 'learning_rate': 8.613437889859205e-06, 'epoch': 0.7128854036713598}
{'loss': 0.0643, 'grad_norm': 4.18171501159668, 'learning_rate': 7.276777757975406e-06, 'epoch': 0.7574407414008199}
{'loss': 0.0682, 'grad_norm': 0.05008452758193016, 'learning_rate': 5.940117626091606e-06, 'epoch': 0.8019960791302798}
{'loss': 0.0698, 'grad_norm': 0.08257556706666946, 'learning_rate': 4.603457494207806e-06, 'epoch': 0.8465514168597398}
{'loss': 0.0689, 'grad_norm': 6.357962608337402, 'learning_rate': 3.2667973623240064e-06, 'epoch': 0.8911067545891997}
{'loss': 0.057, 'grad_norm': 209.90573120117188, 'learning_rate': 1.9301372304402065e-06, 'epoch': 0.9356620923186598}
{'loss': 0.054, 'grad_norm': 0.028873855248093605, 'learning_rate': 5.93477098556407e-07, 'epoch': 0.9802174300481198}
{'eval_loss': 0.2668308615684509, 'eval_runtime': 2307.6273, 'eval_samples_per_second': 178.456, 'eval_steps_per_second': 0.697, 'epoch': 1.0}
{'train_runtime': 5338.6621, 'train_samples_per_second': 33.63, 'train_steps_per_second': 2.102, 'train_loss': 0.13139481647323528, 'epoch': 1.0}
Post-processing 524311 example predictions split into 1379527 features.
{
    "154": {
        "QA": {
            "exact_match": 92.24808535234334,
            "f1": 97.34976769609088
        },
        "PR": {
            "p@1": 0.9875307066133616,
            "p@2": 0.9984104811906941,
            "p@3": 0.9998013101488368
        },
        "PRQA": {
            "exact_match": 91.35699147439911,
            "f1": 96.54700300831972
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 506630 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 506630 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
