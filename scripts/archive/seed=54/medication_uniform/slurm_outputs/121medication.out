2024-05-07 12:33:53 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 121 ---------------
2024-05-07 12:33:53 INFO     Contexts were splited into 544 paragraphs, which are 2.9726775956284155 paragraphs on average per one report. The overall paragraph average length (characters) is 2211.9025735294117
2024-05-07 12:33:54 INFO     Contexts were splited into 81 paragraphs, which are 3.1153846153846154 paragraphs on average per one report. The overall paragraph average length (characters) is 2235.9753086419755
2024-05-07 12:33:54 INFO     Contexts were splited into 149 paragraphs, which are 2.811320754716981 paragraphs on average per one report. The overall paragraph average length (characters) is 2275.046979865772
2024-05-07 12:34:01 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 12:36:50 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 13:33:07 INFO     the model is trained
2024-05-07 13:38:26 INFO     evaluation data are prepared
2024-05-07 14:44:34 INFO     QA scores: {'exact_match': 30.56140200163223, 'f1': 72.70186358996347}
2024-05-07 14:44:34 INFO     PR scores: {'p@1': 0.9422275675443494, 'p@2': 0.9951462566040977, 'p@3': 0.9995060349641338}
2024-05-07 14:44:37 INFO     PRQA scores: {'exact_match': 30.06528929169709, 'f1': 70.66483060661146}
{'loss': 1.2517, 'grad_norm': 8.287753105163574, 'learning_rate': 2.8560046078525487e-05, 'epoch': 0.047998464049150424}
{'loss': 0.7834, 'grad_norm': 5.043795108795166, 'learning_rate': 2.7120092157050974e-05, 'epoch': 0.09599692809830085}
{'loss': 0.6808, 'grad_norm': 5.958395957946777, 'learning_rate': 2.5680138235576463e-05, 'epoch': 0.14399539214745127}
{'loss': 0.6167, 'grad_norm': 6.599165916442871, 'learning_rate': 2.424018431410195e-05, 'epoch': 0.1919938561966017}
{'loss': 0.5967, 'grad_norm': 8.512434005737305, 'learning_rate': 2.2800230392627436e-05, 'epoch': 0.23999232024575212}
{'loss': 0.4964, 'grad_norm': 16.283676147460938, 'learning_rate': 2.1360276471152923e-05, 'epoch': 0.28799078429490255}
{'loss': 0.471, 'grad_norm': 12.533127784729004, 'learning_rate': 1.9920322549678412e-05, 'epoch': 0.33598924834405297}
{'loss': 0.4305, 'grad_norm': 9.461531639099121, 'learning_rate': 1.84803686282039e-05, 'epoch': 0.3839877123932034}
{'loss': 0.4068, 'grad_norm': 10.750073432922363, 'learning_rate': 1.7040414706729385e-05, 'epoch': 0.4319861764423538}
{'loss': 0.3572, 'grad_norm': 7.089498519897461, 'learning_rate': 1.5600460785254872e-05, 'epoch': 0.47998464049150424}
{'loss': 0.346, 'grad_norm': 10.160591125488281, 'learning_rate': 1.4160506863780358e-05, 'epoch': 0.5279831045406547}
{'loss': 0.3022, 'grad_norm': 13.470221519470215, 'learning_rate': 1.2720552942305846e-05, 'epoch': 0.5759815685898051}
{'loss': 0.2902, 'grad_norm': 14.286893844604492, 'learning_rate': 1.1280599020831333e-05, 'epoch': 0.6239800326389555}
{'loss': 0.2694, 'grad_norm': 5.117127418518066, 'learning_rate': 9.84064509935682e-06, 'epoch': 0.6719784966881059}
{'loss': 0.2301, 'grad_norm': 0.1400074064731598, 'learning_rate': 8.400691177882307e-06, 'epoch': 0.7199769607372564}
{'loss': 0.2499, 'grad_norm': 12.7655668258667, 'learning_rate': 6.9607372564077944e-06, 'epoch': 0.7679754247864068}
{'loss': 0.2326, 'grad_norm': 19.027830123901367, 'learning_rate': 5.520783334933282e-06, 'epoch': 0.8159738888355572}
{'loss': 0.2093, 'grad_norm': 15.826229095458984, 'learning_rate': 4.080829413458769e-06, 'epoch': 0.8639723528847076}
{'loss': 0.1844, 'grad_norm': 1.6530287265777588, 'learning_rate': 2.6408754919842566e-06, 'epoch': 0.9119708169338581}
{'loss': 0.2014, 'grad_norm': 3.524919271469116, 'learning_rate': 1.2009215705097437e-06, 'epoch': 0.9599692809830085}
{'eval_loss': 1.2751256227493286, 'eval_runtime': 574.041, 'eval_samples_per_second': 180.372, 'eval_steps_per_second': 0.706, 'epoch': 1.0}
{'train_runtime': 3377.2077, 'train_samples_per_second': 49.35, 'train_steps_per_second': 3.085, 'train_loss': 0.4209190559808336, 'epoch': 1.0}
Post-processing 145864 example predictions split into 389932 features.
{
    "121": {
        "QA": {
            "exact_match": 30.56140200163223,
            "f1": 72.70186358996347
        },
        "PR": {
            "p@1": 0.9422275675443494,
            "p@2": 0.9951462566040977,
            "p@3": 0.9995060349641338
        },
        "PRQA": {
            "exact_match": 30.06528929169709,
            "f1": 70.66483060661146
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 631019 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 631019 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
