2024-05-07 14:32:51 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 77 ---------------
2024-05-07 14:32:52 INFO     Contexts were splited into 1288 paragraphs, which are 7.038251366120218 paragraphs on average per one report. The overall paragraph average length (characters) is 934.2197204968944
2024-05-07 14:32:52 INFO     Contexts were splited into 194 paragraphs, which are 7.461538461538462 paragraphs on average per one report. The overall paragraph average length (characters) is 933.5773195876288
2024-05-07 14:32:52 INFO     Contexts were splited into 361 paragraphs, which are 6.811320754716981 paragraphs on average per one report. The overall paragraph average length (characters) is 939.0083102493074
2024-05-07 14:33:01 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 14:34:16 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 14:57:04 INFO     the model is trained
2024-05-07 15:01:54 INFO     evaluation data are prepared
2024-05-07 16:05:26 INFO     QA scores: {'exact_match': 30.37670203169967, 'f1': 73.62965009765149}
2024-05-07 16:05:26 INFO     PR scores: {'p@1': 0.8822000773162665, 'p@2': 0.9770198874618787, 'p@3': 0.9923542803144195}
2024-05-07 16:05:29 INFO     PRQA scores: {'exact_match': 29.06017782741291, 'f1': 68.97511961270358}
{'loss': 1.7261, 'grad_norm': 12.518835067749023, 'learning_rate': 2.6435361216730037e-05, 'epoch': 0.1188212927756654}
{'loss': 1.1257, 'grad_norm': 7.407449722290039, 'learning_rate': 2.2870722433460076e-05, 'epoch': 0.2376425855513308}
{'loss': 0.9243, 'grad_norm': 7.588850975036621, 'learning_rate': 1.9306083650190115e-05, 'epoch': 0.3564638783269962}
{'loss': 0.7776, 'grad_norm': 12.914397239685059, 'learning_rate': 1.5741444866920154e-05, 'epoch': 0.4752851711026616}
{'loss': 0.6687, 'grad_norm': 11.728865623474121, 'learning_rate': 1.217680608365019e-05, 'epoch': 0.594106463878327}
{'loss': 0.5677, 'grad_norm': 10.49810791015625, 'learning_rate': 8.612167300380228e-06, 'epoch': 0.7129277566539924}
{'loss': 0.4967, 'grad_norm': 22.772640228271484, 'learning_rate': 5.047528517110266e-06, 'epoch': 0.8317490494296578}
{'loss': 0.4572, 'grad_norm': 13.818434715270996, 'learning_rate': 1.4828897338403043e-06, 'epoch': 0.9505703422053232}
{'eval_loss': 1.813215970993042, 'eval_runtime': 237.9662, 'eval_samples_per_second': 180.198, 'eval_steps_per_second': 0.706, 'epoch': 1.0}
{'train_runtime': 1366.6232, 'train_samples_per_second': 49.264, 'train_steps_per_second': 3.079, 'train_loss': 0.8233782021265066, 'epoch': 1.0}
Post-processing 354547 example predictions split into 370182 features.
{
    "77": {
        "QA": {
            "exact_match": 30.37670203169967,
            "f1": 73.62965009765149
        },
        "PR": {
            "p@1": 0.8822000773162665,
            "p@2": 0.9770198874618787,
            "p@3": 0.9923542803144195
        },
        "PRQA": {
            "exact_match": 29.06017782741291,
            "f1": 68.97511961270358
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 1199588 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 1199588 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
