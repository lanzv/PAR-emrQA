2024-05-07 17:38:25 INFO     ------------- Experiment: model BERTbase, frequency threshold 229 ---------------
2024-05-07 17:38:25 INFO     Contexts were splited into 206 paragraphs, which are 1.1256830601092895 paragraphs on average per one report. The overall paragraph average length (characters) is 5841.140776699029
2024-05-07 17:38:26 INFO     Contexts were splited into 33 paragraphs, which are 1.2692307692307692 paragraphs on average per one report. The overall paragraph average length (characters) is 5488.30303030303
2024-05-07 17:38:26 INFO     Contexts were splited into 58 paragraphs, which are 1.0943396226415094 paragraphs on average per one report. The overall paragraph average length (characters) is 5844.517241379311
2024-05-07 17:38:34 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 17:43:32 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 19:30:48 INFO     the model is trained
2024-05-07 19:36:29 INFO     evaluation data are prepared
2024-05-07 20:48:52 INFO     QA scores: {'exact_match': 28.946351101756797, 'f1': 67.74725561138077}
2024-05-07 20:48:52 INFO     PR scores: {'p@1': 0.9911086293544091, 'p@2': 1.0, 'p@3': 1.0}
2024-05-07 20:48:55 INFO     PRQA scores: {'exact_match': 28.74661741334135, 'f1': 67.49673391200913}
{'loss': 1.019, 'grad_norm': 8.25034236907959, 'learning_rate': 2.9243646631706335e-05, 'epoch': 0.025211778943122227}
{'loss': 0.7069, 'grad_norm': 9.41157341003418, 'learning_rate': 2.848729326341267e-05, 'epoch': 0.050423557886244454}
{'loss': 0.6401, 'grad_norm': 11.402596473693848, 'learning_rate': 2.7730939895119003e-05, 'epoch': 0.07563533682936668}
{'loss': 0.5712, 'grad_norm': 11.449178695678711, 'learning_rate': 2.697458652682533e-05, 'epoch': 0.10084711577248891}
{'loss': 0.5102, 'grad_norm': 7.024725914001465, 'learning_rate': 2.6218233158531665e-05, 'epoch': 0.12605889471561113}
{'loss': 0.5091, 'grad_norm': 9.692676544189453, 'learning_rate': 2.5461879790238e-05, 'epoch': 0.15127067365873337}
{'loss': 0.4925, 'grad_norm': 11.437935829162598, 'learning_rate': 2.4705526421944333e-05, 'epoch': 0.17648245260185558}
{'loss': 0.4514, 'grad_norm': 12.500161170959473, 'learning_rate': 2.3949173053650668e-05, 'epoch': 0.20169423154497781}
{'loss': 0.4689, 'grad_norm': 12.772919654846191, 'learning_rate': 2.3192819685357002e-05, 'epoch': 0.22690601048810005}
{'loss': 0.4103, 'grad_norm': 8.72520637512207, 'learning_rate': 2.2436466317063333e-05, 'epoch': 0.25211778943122226}
{'loss': 0.3933, 'grad_norm': 22.502592086791992, 'learning_rate': 2.1680112948769663e-05, 'epoch': 0.27732956837434447}
{'loss': 0.3923, 'grad_norm': 5.531539440155029, 'learning_rate': 2.0923759580475998e-05, 'epoch': 0.30254134731746674}
{'loss': 0.3592, 'grad_norm': 8.621586799621582, 'learning_rate': 2.0167406212182332e-05, 'epoch': 0.32775312626058895}
{'loss': 0.3378, 'grad_norm': 5.461294174194336, 'learning_rate': 1.9411052843888666e-05, 'epoch': 0.35296490520371115}
{'loss': 0.3388, 'grad_norm': 6.640399932861328, 'learning_rate': 1.8654699475595e-05, 'epoch': 0.3781766841468334}
{'loss': 0.3208, 'grad_norm': 4.550632953643799, 'learning_rate': 1.7898346107301334e-05, 'epoch': 0.40338846308995563}
{'loss': 0.2971, 'grad_norm': 9.678726196289062, 'learning_rate': 1.7141992739007665e-05, 'epoch': 0.42860024203307784}
{'loss': 0.2701, 'grad_norm': 5.330976963043213, 'learning_rate': 1.6385639370713996e-05, 'epoch': 0.4538120209762001}
{'loss': 0.2738, 'grad_norm': 16.57837677001953, 'learning_rate': 1.562928600242033e-05, 'epoch': 0.4790237999193223}
{'loss': 0.2654, 'grad_norm': 13.1944580078125, 'learning_rate': 1.4872932634126664e-05, 'epoch': 0.5042355788624445}
{'loss': 0.2682, 'grad_norm': 12.87128734588623, 'learning_rate': 1.4116579265832997e-05, 'epoch': 0.5294473578055667}
{'loss': 0.2399, 'grad_norm': 10.409196853637695, 'learning_rate': 1.3360225897539331e-05, 'epoch': 0.5546591367486889}
{'loss': 0.2291, 'grad_norm': 14.734675407409668, 'learning_rate': 1.2603872529245664e-05, 'epoch': 0.5798709156918113}
{'loss': 0.2359, 'grad_norm': 9.382599830627441, 'learning_rate': 1.1847519160951998e-05, 'epoch': 0.6050826946349335}
{'loss': 0.222, 'grad_norm': 11.002975463867188, 'learning_rate': 1.109116579265833e-05, 'epoch': 0.6302944735780557}
{'loss': 0.2196, 'grad_norm': 15.60688304901123, 'learning_rate': 1.0334812424364663e-05, 'epoch': 0.6555062525211779}
{'loss': 0.1994, 'grad_norm': 16.655426025390625, 'learning_rate': 9.578459056070997e-06, 'epoch': 0.6807180314643001}
{'loss': 0.1945, 'grad_norm': 4.253598213195801, 'learning_rate': 8.82210568777733e-06, 'epoch': 0.7059298104074223}
{'loss': 0.1779, 'grad_norm': 13.38254451751709, 'learning_rate': 8.065752319483664e-06, 'epoch': 0.7311415893505446}
{'loss': 0.1776, 'grad_norm': 20.152206420898438, 'learning_rate': 7.309398951189996e-06, 'epoch': 0.7563533682936668}
{'loss': 0.1848, 'grad_norm': 18.69381332397461, 'learning_rate': 6.55304558289633e-06, 'epoch': 0.781565147236789}
{'loss': 0.1637, 'grad_norm': 13.503005981445312, 'learning_rate': 5.796692214602662e-06, 'epoch': 0.8067769261799113}
{'loss': 0.1732, 'grad_norm': 13.218838691711426, 'learning_rate': 5.0403388463089954e-06, 'epoch': 0.8319887051230335}
{'loss': 0.1608, 'grad_norm': 15.029205322265625, 'learning_rate': 4.283985478015329e-06, 'epoch': 0.8572004840661557}
{'loss': 0.1606, 'grad_norm': 17.014162063598633, 'learning_rate': 3.527632109721662e-06, 'epoch': 0.8824122630092779}
{'loss': 0.1689, 'grad_norm': 6.796608924865723, 'learning_rate': 2.771278741427995e-06, 'epoch': 0.9076240419524002}
{'loss': 0.1567, 'grad_norm': 18.902271270751953, 'learning_rate': 2.0149253731343284e-06, 'epoch': 0.9328358208955224}
{'loss': 0.1459, 'grad_norm': 0.31010153889656067, 'learning_rate': 1.2585720048406618e-06, 'epoch': 0.9580475998386446}
{'loss': 0.1543, 'grad_norm': 18.260528564453125, 'learning_rate': 5.022186365469948e-07, 'epoch': 0.9832593787817668}
{'eval_loss': 0.7461424469947815, 'eval_runtime': 1125.8482, 'eval_samples_per_second': 180.316, 'eval_steps_per_second': 0.704, 'epoch': 1.0}
{'train_runtime': 6435.5873, 'train_samples_per_second': 49.304, 'train_steps_per_second': 3.082, 'train_loss': 0.32183021766228653, 'epoch': 1.0}
Post-processing 53341 example predictions split into 432700 features.
{
    "229": {
        "QA": {
            "exact_match": 28.946351101756797,
            "f1": 67.74725561138077
        },
        "PR": {
            "p@1": 0.9911086293544091,
            "p@2": 1.0,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 28.74661741334135,
            "f1": 67.49673391200913
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 631924 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 631924 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
