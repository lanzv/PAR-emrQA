2024-05-07 15:54:26 INFO     ------------- Experiment: model BERTbase, frequency threshold 149 ---------------
2024-05-07 15:54:26 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-07 15:54:26 INFO     Contexts were splited into 864 paragraphs, which are 2.8993288590604025 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 149. The overall paragraph average length (characters) is 1953.5844907407406
2024-05-07 15:54:26 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-07 15:54:26 INFO     Contexts were splited into 127 paragraphs, which are 3.0238095238095237 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 149. The overall paragraph average length (characters) is 1446.2047244094488
2024-05-07 15:54:27 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-07 15:54:27 INFO     Contexts were splited into 252 paragraphs, which are 2.9302325581395348 paragraphs on average per one report. There are 4 unique topics with frequency threshold (greater or equal) 149. The overall paragraph average length (characters) is 1707.6944444444443
2024-05-07 15:55:05 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 16:04:51 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 18:49:51 INFO     the model is trained
2024-05-07 19:13:15 INFO     evaluation data are prepared
2024-05-08 00:15:19 INFO     QA scores: {'exact_match': 89.28820866046915, 'f1': 94.84591718283842}
2024-05-08 00:15:19 INFO     PR scores: {'p@1': 0.991715235296951, 'p@2': 0.9991691151678628, 'p@3': 1.0}
2024-05-08 00:15:29 INFO     PRQA scores: {'exact_match': 88.79208612301912, 'f1': 94.45055807474981}
{'loss': 0.6003, 'grad_norm': 11.662749290466309, 'learning_rate': 2.9297390978500163e-05, 'epoch': 0.0234203007166612}
{'loss': 0.2803, 'grad_norm': 8.133100509643555, 'learning_rate': 2.859478195700033e-05, 'epoch': 0.0468406014333224}
{'loss': 0.2499, 'grad_norm': 11.38267993927002, 'learning_rate': 2.7892172935500494e-05, 'epoch': 0.07026090214998361}
{'loss': 0.2116, 'grad_norm': 2.1435699462890625, 'learning_rate': 2.7189563914000656e-05, 'epoch': 0.0936812028666448}
{'loss': 0.2009, 'grad_norm': 23.78137969970703, 'learning_rate': 2.6486954892500822e-05, 'epoch': 0.11710150358330601}
{'loss': 0.2085, 'grad_norm': 10.689169883728027, 'learning_rate': 2.5784345871000984e-05, 'epoch': 0.14052180429996722}
{'loss': 0.1867, 'grad_norm': 3.714431047439575, 'learning_rate': 2.5081736849501146e-05, 'epoch': 0.16394210501662843}
{'loss': 0.1735, 'grad_norm': 2.2791881561279297, 'learning_rate': 2.4379127828001312e-05, 'epoch': 0.1873624057332896}
{'loss': 0.1718, 'grad_norm': 7.8680806159973145, 'learning_rate': 2.3676518806501477e-05, 'epoch': 0.2107827064499508}
{'loss': 0.1552, 'grad_norm': 3.893051862716675, 'learning_rate': 2.297390978500164e-05, 'epoch': 0.23420300716661202}
{'loss': 0.1551, 'grad_norm': 4.22270393371582, 'learning_rate': 2.2271300763501802e-05, 'epoch': 0.2576233078832732}
{'loss': 0.1482, 'grad_norm': 0.2336629033088684, 'learning_rate': 2.156869174200197e-05, 'epoch': 0.28104360859993444}
{'loss': 0.1345, 'grad_norm': 2.0381577014923096, 'learning_rate': 2.0866082720502133e-05, 'epoch': 0.3044639093165956}
{'loss': 0.1511, 'grad_norm': 15.338616371154785, 'learning_rate': 2.0163473699002295e-05, 'epoch': 0.32788421003325685}
{'loss': 0.1346, 'grad_norm': 9.365154266357422, 'learning_rate': 1.946086467750246e-05, 'epoch': 0.35130451074991803}
{'loss': 0.1169, 'grad_norm': 0.6931559443473816, 'learning_rate': 1.8758255656002623e-05, 'epoch': 0.3747248114665792}
{'loss': 0.1376, 'grad_norm': 5.251887321472168, 'learning_rate': 1.805564663450279e-05, 'epoch': 0.39814511218324045}
{'loss': 0.1226, 'grad_norm': 0.4157029390335083, 'learning_rate': 1.735303761300295e-05, 'epoch': 0.4215654128999016}
{'loss': 0.1152, 'grad_norm': 0.03594428300857544, 'learning_rate': 1.6650428591503116e-05, 'epoch': 0.44498571361656286}
{'loss': 0.1168, 'grad_norm': 8.975655555725098, 'learning_rate': 1.594781957000328e-05, 'epoch': 0.46840601433322404}
{'loss': 0.0963, 'grad_norm': 4.2968902587890625, 'learning_rate': 1.5245210548503442e-05, 'epoch': 0.4918263150498852}
{'loss': 0.0981, 'grad_norm': 0.20608970522880554, 'learning_rate': 1.4542601527003606e-05, 'epoch': 0.5152466157665464}
{'loss': 0.1015, 'grad_norm': 4.51995849609375, 'learning_rate': 1.3839992505503772e-05, 'epoch': 0.5386669164832076}
{'loss': 0.0904, 'grad_norm': 14.208739280700684, 'learning_rate': 1.3137383484003934e-05, 'epoch': 0.5620872171998689}
{'loss': 0.0928, 'grad_norm': 0.14630207419395447, 'learning_rate': 1.2434774462504098e-05, 'epoch': 0.58550751791653}
{'loss': 0.0865, 'grad_norm': 0.7859008312225342, 'learning_rate': 1.1732165441004264e-05, 'epoch': 0.6089278186331912}
{'loss': 0.0905, 'grad_norm': 0.021402942016720772, 'learning_rate': 1.1029556419504426e-05, 'epoch': 0.6323481193498525}
{'loss': 0.0873, 'grad_norm': 0.13096456229686737, 'learning_rate': 1.0326947398004591e-05, 'epoch': 0.6557684200665137}
{'loss': 0.0865, 'grad_norm': 0.1105944961309433, 'learning_rate': 9.624338376504753e-06, 'epoch': 0.6791887207831748}
{'loss': 0.082, 'grad_norm': 0.03531939536333084, 'learning_rate': 8.921729355004919e-06, 'epoch': 0.7026090214998361}
{'loss': 0.0765, 'grad_norm': 0.9656001925468445, 'learning_rate': 8.219120333505083e-06, 'epoch': 0.7260293222164973}
{'loss': 0.087, 'grad_norm': 0.015815788879990578, 'learning_rate': 7.516511312005246e-06, 'epoch': 0.7494496229331584}
{'loss': 0.0754, 'grad_norm': 2.1281442642211914, 'learning_rate': 6.813902290505411e-06, 'epoch': 0.7728699236498197}
{'loss': 0.0757, 'grad_norm': 14.873676300048828, 'learning_rate': 6.111293269005575e-06, 'epoch': 0.7962902243664809}
{'loss': 0.0796, 'grad_norm': 0.020853407680988312, 'learning_rate': 5.408684247505738e-06, 'epoch': 0.819710525083142}
{'loss': 0.0673, 'grad_norm': 1.0717620849609375, 'learning_rate': 4.7060752260059015e-06, 'epoch': 0.8431308257998033}
{'loss': 0.0623, 'grad_norm': 0.050942208617925644, 'learning_rate': 4.003466204506066e-06, 'epoch': 0.8665511265164645}
{'loss': 0.0658, 'grad_norm': 0.07827835530042648, 'learning_rate': 3.30085718300623e-06, 'epoch': 0.8899714272331257}
{'loss': 0.0522, 'grad_norm': 7.540469646453857, 'learning_rate': 2.5982481615063936e-06, 'epoch': 0.9133917279497868}
{'loss': 0.0563, 'grad_norm': 12.96751594543457, 'learning_rate': 1.8956391400065575e-06, 'epoch': 0.9368120286664481}
{'loss': 0.0613, 'grad_norm': 11.173301696777344, 'learning_rate': 1.1930301185067218e-06, 'epoch': 0.9602323293831093}
{'loss': 0.0572, 'grad_norm': 0.36569252610206604, 'learning_rate': 4.904210970068856e-07, 'epoch': 0.9836526300997704}
{'eval_loss': 0.24602949619293213, 'eval_runtime': 4090.1841, 'eval_samples_per_second': 178.059, 'eval_steps_per_second': 0.696, 'epoch': 1.0}
{'train_runtime': 9898.4878, 'train_samples_per_second': 34.508, 'train_steps_per_second': 2.157, 'train_loss': 0.12981259626852856, 'epoch': 1.0}
Post-processing 492433 example predictions split into 1778982 features.
{
    "149": {
        "QA": {
            "exact_match": 89.28820866046915,
            "f1": 94.84591718283842
        },
        "PR": {
            "p@1": 0.991715235296951,
            "p@2": 0.9991691151678628,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.79208612301912,
            "f1": 94.45055807474981
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3652484 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3652484 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
