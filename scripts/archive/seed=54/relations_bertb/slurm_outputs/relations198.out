2024-05-07 16:06:52 INFO     ------------- Experiment: model BERTbase, frequency threshold 198 ---------------
2024-05-07 16:06:52 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-07 16:06:52 INFO     Contexts were splited into 298 paragraphs, which are 1.0 paragraphs on average per one report. There are 0 unique topics with frequency threshold (greater or equal) 198. The overall paragraph average length (characters) is 5664.083892617449
2024-05-07 16:06:53 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-07 16:06:53 INFO     Contexts were splited into 42 paragraphs, which are 1.0 paragraphs on average per one report. There are 0 unique topics with frequency threshold (greater or equal) 198. The overall paragraph average length (characters) is 4373.047619047619
2024-05-07 16:06:53 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-07 16:06:53 INFO     Contexts were splited into 86 paragraphs, which are 1.0 paragraphs on average per one report. There are 0 unique topics with frequency threshold (greater or equal) 198. The overall paragraph average length (characters) is 5003.941860465116
2024-05-07 16:07:29 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 16:16:42 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 18:47:06 INFO     the model is trained
2024-05-07 19:07:23 INFO     evaluation data are prepared
2024-05-07 23:18:59 INFO     QA scores: {'exact_match': 88.88541014402004, 'f1': 94.58984978097256}
2024-05-07 23:18:59 INFO     PR scores: {'p@1': 1.0, 'p@2': 1.0, 'p@3': 1.0}
2024-05-07 23:19:09 INFO     PRQA scores: {'exact_match': 88.88541014402004, 'f1': 94.58984978097256}
{'loss': 0.6014, 'grad_norm': 2.715059280395508, 'learning_rate': 2.9248722828808976e-05, 'epoch': 0.025042572373034158}
{'loss': 0.2854, 'grad_norm': 10.337209701538086, 'learning_rate': 2.849744565761795e-05, 'epoch': 0.050085144746068316}
{'loss': 0.2746, 'grad_norm': 16.97226905822754, 'learning_rate': 2.7746168486426926e-05, 'epoch': 0.07512771711910247}
{'loss': 0.2407, 'grad_norm': 2.5507919788360596, 'learning_rate': 2.6994891315235905e-05, 'epoch': 0.10017028949213663}
{'loss': 0.2271, 'grad_norm': 5.853470325469971, 'learning_rate': 2.6243614144044877e-05, 'epoch': 0.12521286186517078}
{'loss': 0.2047, 'grad_norm': 18.717529296875, 'learning_rate': 2.5492336972853852e-05, 'epoch': 0.15025543423820495}
{'loss': 0.2004, 'grad_norm': 36.343563079833984, 'learning_rate': 2.4741059801662827e-05, 'epoch': 0.1752980066112391}
{'loss': 0.1724, 'grad_norm': 8.851995468139648, 'learning_rate': 2.3989782630471803e-05, 'epoch': 0.20034057898427327}
{'loss': 0.1735, 'grad_norm': 8.047073364257812, 'learning_rate': 2.3238505459280778e-05, 'epoch': 0.2253831513573074}
{'loss': 0.1706, 'grad_norm': 1.3850246667861938, 'learning_rate': 2.2487228288089753e-05, 'epoch': 0.25042572373034155}
{'loss': 0.1684, 'grad_norm': 2.350017547607422, 'learning_rate': 2.1735951116898728e-05, 'epoch': 0.27546829610337575}
{'loss': 0.1639, 'grad_norm': 0.3924812376499176, 'learning_rate': 2.0984673945707707e-05, 'epoch': 0.3005108684764099}
{'loss': 0.1462, 'grad_norm': 6.3213067054748535, 'learning_rate': 2.023339677451668e-05, 'epoch': 0.32555344084944404}
{'loss': 0.1344, 'grad_norm': 13.944114685058594, 'learning_rate': 1.9482119603325654e-05, 'epoch': 0.3505960132224782}
{'loss': 0.1369, 'grad_norm': 1.830512285232544, 'learning_rate': 1.873084243213463e-05, 'epoch': 0.3756385855955124}
{'loss': 0.1371, 'grad_norm': 0.025202231481671333, 'learning_rate': 1.7979565260943604e-05, 'epoch': 0.40068115796854653}
{'loss': 0.1419, 'grad_norm': 10.004326820373535, 'learning_rate': 1.722828808975258e-05, 'epoch': 0.4257237303415807}
{'loss': 0.1136, 'grad_norm': 3.5024096965789795, 'learning_rate': 1.6477010918561555e-05, 'epoch': 0.4507663027146148}
{'loss': 0.1117, 'grad_norm': 5.234635829925537, 'learning_rate': 1.572573374737053e-05, 'epoch': 0.475808875087649}
{'loss': 0.1107, 'grad_norm': 3.3339455127716064, 'learning_rate': 1.4974456576179505e-05, 'epoch': 0.5008514474606831}
{'loss': 0.1133, 'grad_norm': 8.986532211303711, 'learning_rate': 1.422317940498848e-05, 'epoch': 0.5258940198337173}
{'loss': 0.1052, 'grad_norm': 6.724161624908447, 'learning_rate': 1.3471902233797457e-05, 'epoch': 0.5509365922067515}
{'loss': 0.1049, 'grad_norm': 9.749855041503906, 'learning_rate': 1.2720625062606431e-05, 'epoch': 0.5759791645797856}
{'loss': 0.1104, 'grad_norm': 8.2894926071167, 'learning_rate': 1.1969347891415406e-05, 'epoch': 0.6010217369528198}
{'loss': 0.0973, 'grad_norm': 2.6646578311920166, 'learning_rate': 1.1218070720224381e-05, 'epoch': 0.626064309325854}
{'loss': 0.1003, 'grad_norm': 3.7080066204071045, 'learning_rate': 1.0466793549033358e-05, 'epoch': 0.6511068816988881}
{'loss': 0.0921, 'grad_norm': 0.025715144351124763, 'learning_rate': 9.715516377842332e-06, 'epoch': 0.6761494540719223}
{'loss': 0.0813, 'grad_norm': 13.730147361755371, 'learning_rate': 8.964239206651307e-06, 'epoch': 0.7011920264449564}
{'loss': 0.0891, 'grad_norm': 0.006896705832332373, 'learning_rate': 8.212962035460282e-06, 'epoch': 0.7262345988179906}
{'loss': 0.0886, 'grad_norm': 16.073301315307617, 'learning_rate': 7.461684864269258e-06, 'epoch': 0.7512771711910248}
{'loss': 0.0803, 'grad_norm': 0.05868158116936684, 'learning_rate': 6.710407693078234e-06, 'epoch': 0.7763197435640589}
{'loss': 0.0752, 'grad_norm': 0.01832653023302555, 'learning_rate': 5.959130521887208e-06, 'epoch': 0.8013623159370931}
{'loss': 0.0692, 'grad_norm': 14.179736137390137, 'learning_rate': 5.207853350696184e-06, 'epoch': 0.8264048883101273}
{'loss': 0.0763, 'grad_norm': 12.493943214416504, 'learning_rate': 4.4565761795051585e-06, 'epoch': 0.8514474606831614}
{'loss': 0.0739, 'grad_norm': 22.9960994720459, 'learning_rate': 3.705299008314134e-06, 'epoch': 0.8764900330561955}
{'loss': 0.0727, 'grad_norm': 0.16629815101623535, 'learning_rate': 2.9540218371231094e-06, 'epoch': 0.9015326054292296}
{'loss': 0.0674, 'grad_norm': 0.22104394435882568, 'learning_rate': 2.2027446659320846e-06, 'epoch': 0.9265751778022638}
{'loss': 0.0772, 'grad_norm': 15.865687370300293, 'learning_rate': 1.4514674947410598e-06, 'epoch': 0.951617750175298}
{'loss': 0.0638, 'grad_norm': 1.216596007347107, 'learning_rate': 7.001903235500351e-07, 'epoch': 0.9766603225483321}
{'eval_loss': 0.27090325951576233, 'eval_runtime': 3697.5387, 'eval_samples_per_second': 181.451, 'eval_steps_per_second': 0.709, 'epoch': 1.0}
{'train_runtime': 9022.7994, 'train_samples_per_second': 35.404, 'train_steps_per_second': 2.213, 'train_loss': 0.1407089952738075, 'epoch': 1.0}
Post-processing 166088 example predictions split into 1509630 features.
{
    "198": {
        "QA": {
            "exact_match": 88.88541014402004,
            "f1": 94.58984978097256
        },
        "PR": {
            "p@1": 1.0,
            "p@2": 1.0,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.88541014402004,
            "f1": 94.58984978097256
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 3166628 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 3166628 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
