2024-05-07 20:49:14 INFO     ------------- Experiment: model BERTbase, frequency threshold 190 ---------------
2024-05-07 20:49:14 INFO     Contexts were splited into 525 paragraphs, which are 1.761744966442953 paragraphs on average per one report. The overall paragraph average length (characters) is 3151.7542857142857
2024-05-07 20:49:14 INFO     Contexts were splited into 63 paragraphs, which are 1.5 paragraphs on average per one report. The overall paragraph average length (characters) is 2857.095238095238
2024-05-07 20:49:15 INFO     Contexts were splited into 140 paragraphs, which are 1.627906976744186 paragraphs on average per one report. The overall paragraph average length (characters) is 3012.692857142857
2024-05-07 20:49:45 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 20:57:19 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 22:56:20 INFO     the model is trained
2024-05-07 23:17:41 INFO     evaluation data are prepared
2024-05-08 03:32:29 INFO     QA scores: {'exact_match': 90.18050671932951, 'f1': 95.78487227985836}
2024-05-08 03:32:29 INFO     PR scores: {'p@1': 0.9844359616588796, 'p@2': 0.9968992341409373, 'p@3': 0.9993377004961226}
2024-05-08 03:32:39 INFO     PRQA scores: {'exact_match': 89.34299889215356, 'f1': 95.05001602314134}
{'loss': 0.6512, 'grad_norm': 10.251043319702148, 'learning_rate': 2.9021909233176843e-05, 'epoch': 0.03260302556077204}
{'loss': 0.331, 'grad_norm': 4.84644079208374, 'learning_rate': 2.8043818466353678e-05, 'epoch': 0.06520605112154408}
{'loss': 0.273, 'grad_norm': 11.999167442321777, 'learning_rate': 2.706572769953052e-05, 'epoch': 0.09780907668231612}
{'loss': 0.242, 'grad_norm': 5.411610126495361, 'learning_rate': 2.6087636932707354e-05, 'epoch': 0.13041210224308816}
{'loss': 0.222, 'grad_norm': 1.0132668018341064, 'learning_rate': 2.5109546165884196e-05, 'epoch': 0.1630151278038602}
{'loss': 0.2016, 'grad_norm': 10.996257781982422, 'learning_rate': 2.413145539906103e-05, 'epoch': 0.19561815336463223}
{'loss': 0.1923, 'grad_norm': 1.506748914718628, 'learning_rate': 2.3153364632237873e-05, 'epoch': 0.22822117892540428}
{'loss': 0.188, 'grad_norm': 2.5548412799835205, 'learning_rate': 2.217527386541471e-05, 'epoch': 0.2608242044861763}
{'loss': 0.1735, 'grad_norm': 5.337738990783691, 'learning_rate': 2.119718309859155e-05, 'epoch': 0.2934272300469484}
{'loss': 0.1667, 'grad_norm': 19.845279693603516, 'learning_rate': 2.0219092331768388e-05, 'epoch': 0.3260302556077204}
{'loss': 0.1605, 'grad_norm': 7.566417694091797, 'learning_rate': 1.9241001564945226e-05, 'epoch': 0.3586332811684924}
{'loss': 0.1513, 'grad_norm': 18.680017471313477, 'learning_rate': 1.8262910798122068e-05, 'epoch': 0.39123630672926446}
{'loss': 0.145, 'grad_norm': 0.6272269487380981, 'learning_rate': 1.7284820031298903e-05, 'epoch': 0.4238393322900365}
{'loss': 0.14, 'grad_norm': 0.03610751032829285, 'learning_rate': 1.6306729264475745e-05, 'epoch': 0.45644235785080856}
{'loss': 0.112, 'grad_norm': 0.6996568441390991, 'learning_rate': 1.5328638497652583e-05, 'epoch': 0.4890453834115806}
{'loss': 0.1156, 'grad_norm': 8.884429931640625, 'learning_rate': 1.4350547730829422e-05, 'epoch': 0.5216484089723527}
{'loss': 0.112, 'grad_norm': 1.6699855327606201, 'learning_rate': 1.337245696400626e-05, 'epoch': 0.5542514345331246}
{'loss': 0.1025, 'grad_norm': 2.902794599533081, 'learning_rate': 1.23943661971831e-05, 'epoch': 0.5868544600938967}
{'loss': 0.1084, 'grad_norm': 1.1503857374191284, 'learning_rate': 1.1416275430359938e-05, 'epoch': 0.6194574856546687}
{'loss': 0.1016, 'grad_norm': 7.3531599044799805, 'learning_rate': 1.0438184663536777e-05, 'epoch': 0.6520605112154408}
{'loss': 0.0982, 'grad_norm': 0.09055418521165848, 'learning_rate': 9.460093896713615e-06, 'epoch': 0.6846635367762128}
{'loss': 0.1007, 'grad_norm': 0.1419517993927002, 'learning_rate': 8.482003129890454e-06, 'epoch': 0.7172665623369848}
{'loss': 0.089, 'grad_norm': 0.01470225490629673, 'learning_rate': 7.503912363067292e-06, 'epoch': 0.7498695878977569}
{'loss': 0.0712, 'grad_norm': 1.2328736782073975, 'learning_rate': 6.525821596244132e-06, 'epoch': 0.7824726134585289}
{'loss': 0.0832, 'grad_norm': 0.725962221622467, 'learning_rate': 5.5477308294209705e-06, 'epoch': 0.815075639019301}
{'loss': 0.091, 'grad_norm': 0.04544820263981819, 'learning_rate': 4.569640062597809e-06, 'epoch': 0.847678664580073}
{'loss': 0.0829, 'grad_norm': 7.8754754066467285, 'learning_rate': 3.5915492957746477e-06, 'epoch': 0.8802816901408451}
{'loss': 0.0664, 'grad_norm': 0.5091495513916016, 'learning_rate': 2.613458528951487e-06, 'epoch': 0.9128847157016171}
{'loss': 0.0731, 'grad_norm': 34.34441375732422, 'learning_rate': 1.6353677621283255e-06, 'epoch': 0.9454877412623891}
{'loss': 0.0618, 'grad_norm': 0.16918452084064484, 'learning_rate': 6.572769953051644e-07, 'epoch': 0.9780907668231612}
{'eval_loss': 0.2892882227897644, 'eval_runtime': 3031.7979, 'eval_samples_per_second': 180.206, 'eval_steps_per_second': 0.704, 'epoch': 1.0}
{'train_runtime': 7140.4195, 'train_samples_per_second': 34.363, 'train_steps_per_second': 2.148, 'train_loss': 0.1549500159192471, 'epoch': 1.0}
Post-processing 373252 example predictions split into 1504802 features.
{
    "190": {
        "QA": {
            "exact_match": 90.18050671932951,
            "f1": 95.78487227985836
        },
        "PR": {
            "p@1": 0.9844359616588796,
            "p@2": 0.9968992341409373,
            "p@3": 0.9993377004961226
        },
        "PRQA": {
            "exact_match": 89.34299889215356,
            "f1": 95.05001602314134
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 632367 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 632367 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
