2024-05-08 02:56:22 INFO     ------------- Experiment: model BERTbase, frequency threshold 198 ---------------
2024-05-08 02:56:22 INFO     Contexts were splited into 360 paragraphs, which are 1.2080536912751678 paragraphs on average per one report. The overall paragraph average length (characters) is 4596.308333333333
2024-05-08 02:56:22 INFO     Contexts were splited into 47 paragraphs, which are 1.119047619047619 paragraphs on average per one report. The overall paragraph average length (characters) is 3829.723404255319
2024-05-08 02:56:23 INFO     Contexts were splited into 102 paragraphs, which are 1.186046511627907 paragraphs on average per one report. The overall paragraph average length (characters) is 4135.068627450981
2024-05-08 02:56:56 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-08 03:06:07 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-08 05:33:54 INFO     the model is trained
2024-05-08 05:54:23 INFO     evaluation data are prepared
2024-05-08 10:10:27 INFO     QA scores: {'exact_match': 89.39176821925726, 'f1': 95.26671374081278}
2024-05-08 10:10:27 INFO     PR scores: {'p@1': 0.9909325177014595, 'p@2': 0.9994280140648331, 'p@3': 1.0}
2024-05-08 10:10:37 INFO     PRQA scores: {'exact_match': 88.91611675738163, 'f1': 94.84111558779368}
{'loss': 0.5894, 'grad_norm': 7.673027038574219, 'learning_rate': 2.9210401642364586e-05, 'epoch': 0.02631994525451387}
{'loss': 0.3173, 'grad_norm': 6.460190773010254, 'learning_rate': 2.842080328472917e-05, 'epoch': 0.05263989050902774}
{'loss': 0.2518, 'grad_norm': 5.55808162689209, 'learning_rate': 2.7631204927093754e-05, 'epoch': 0.07895983576354161}
{'loss': 0.2479, 'grad_norm': 4.396470546722412, 'learning_rate': 2.6841606569458337e-05, 'epoch': 0.10527978101805548}
{'loss': 0.2294, 'grad_norm': 2.8661346435546875, 'learning_rate': 2.6052008211822922e-05, 'epoch': 0.13159972627256936}
{'loss': 0.2036, 'grad_norm': 13.005043029785156, 'learning_rate': 2.5262409854187504e-05, 'epoch': 0.15791967152708322}
{'loss': 0.1996, 'grad_norm': 8.718890190124512, 'learning_rate': 2.447281149655209e-05, 'epoch': 0.1842396167815971}
{'loss': 0.1841, 'grad_norm': 0.3060561716556549, 'learning_rate': 2.3683213138916672e-05, 'epoch': 0.21055956203611095}
{'loss': 0.1759, 'grad_norm': 1.2503876686096191, 'learning_rate': 2.2893614781281258e-05, 'epoch': 0.23687950729062485}
{'loss': 0.1498, 'grad_norm': 6.616705894470215, 'learning_rate': 2.210401642364584e-05, 'epoch': 0.2631994525451387}
{'loss': 0.1515, 'grad_norm': 0.9459928274154663, 'learning_rate': 2.1314418066010426e-05, 'epoch': 0.2895193977996526}
{'loss': 0.1416, 'grad_norm': 22.362274169921875, 'learning_rate': 2.0524819708375005e-05, 'epoch': 0.31583934305416644}
{'loss': 0.1323, 'grad_norm': 2.532414436340332, 'learning_rate': 1.973522135073959e-05, 'epoch': 0.3421592883086803}
{'loss': 0.135, 'grad_norm': 0.23231598734855652, 'learning_rate': 1.8945622993104173e-05, 'epoch': 0.3684792335631942}
{'loss': 0.1244, 'grad_norm': 0.7046629190444946, 'learning_rate': 1.8156024635468758e-05, 'epoch': 0.39479917881770804}
{'loss': 0.1187, 'grad_norm': 12.178955078125, 'learning_rate': 1.736642627783334e-05, 'epoch': 0.4211191240722219}
{'loss': 0.1304, 'grad_norm': 1.5867164134979248, 'learning_rate': 1.6576827920197926e-05, 'epoch': 0.4474390693267358}
{'loss': 0.1073, 'grad_norm': 0.1778116077184677, 'learning_rate': 1.578722956256251e-05, 'epoch': 0.4737590145812497}
{'loss': 0.1275, 'grad_norm': 2.1639671325683594, 'learning_rate': 1.4997631204927094e-05, 'epoch': 0.5000789598357636}
{'loss': 0.1209, 'grad_norm': 4.247745037078857, 'learning_rate': 1.4208032847291678e-05, 'epoch': 0.5263989050902774}
{'loss': 0.1161, 'grad_norm': 0.07805848866701126, 'learning_rate': 1.3418434489656262e-05, 'epoch': 0.5527188503447913}
{'loss': 0.0998, 'grad_norm': 5.547760963439941, 'learning_rate': 1.2628836132020846e-05, 'epoch': 0.5790387955993052}
{'loss': 0.1009, 'grad_norm': 1.0360766649246216, 'learning_rate': 1.183923777438543e-05, 'epoch': 0.605358740853819}
{'loss': 0.0992, 'grad_norm': 23.418228149414062, 'learning_rate': 1.1049639416750014e-05, 'epoch': 0.6316786861083329}
{'loss': 0.0928, 'grad_norm': 14.528534889221191, 'learning_rate': 1.0260041059114598e-05, 'epoch': 0.6579986313628468}
{'loss': 0.0862, 'grad_norm': 12.342589378356934, 'learning_rate': 9.470442701479182e-06, 'epoch': 0.6843185766173606}
{'loss': 0.0887, 'grad_norm': 0.9021720886230469, 'learning_rate': 8.680844343843766e-06, 'epoch': 0.7106385218718745}
{'loss': 0.077, 'grad_norm': 1.0802202224731445, 'learning_rate': 7.89124598620835e-06, 'epoch': 0.7369584671263884}
{'loss': 0.0799, 'grad_norm': 0.02265176735818386, 'learning_rate': 7.1016476285729325e-06, 'epoch': 0.7632784123809022}
{'loss': 0.0746, 'grad_norm': 0.671251654624939, 'learning_rate': 6.3120492709375165e-06, 'epoch': 0.7895983576354161}
{'loss': 0.0795, 'grad_norm': 0.07129840552806854, 'learning_rate': 5.5224509133021004e-06, 'epoch': 0.81591830288993}
{'loss': 0.0695, 'grad_norm': 0.45132574439048767, 'learning_rate': 4.732852555666684e-06, 'epoch': 0.8422382481444438}
{'loss': 0.0622, 'grad_norm': 0.004803539253771305, 'learning_rate': 3.943254198031268e-06, 'epoch': 0.8685581933989577}
{'loss': 0.0661, 'grad_norm': 7.751338005065918, 'learning_rate': 3.1536558403958523e-06, 'epoch': 0.8948781386534717}
{'loss': 0.0654, 'grad_norm': 0.02162834256887436, 'learning_rate': 2.364057482760436e-06, 'epoch': 0.9211980839079855}
{'loss': 0.068, 'grad_norm': 25.270973205566406, 'learning_rate': 1.5744591251250197e-06, 'epoch': 0.9475180291624994}
{'loss': 0.0658, 'grad_norm': 5.13765811920166, 'learning_rate': 7.848607674896036e-07, 'epoch': 0.9738379744170133}
{'eval_loss': 0.2630094587802887, 'eval_runtime': 3739.2071, 'eval_samples_per_second': 179.175, 'eval_steps_per_second': 0.7, 'epoch': 1.0}
{'train_runtime': 8865.9037, 'train_samples_per_second': 34.283, 'train_steps_per_second': 2.143, 'train_loss': 0.1395400272655934, 'epoch': 1.0}
Post-processing 238640 example predictions split into 1524121 features.
{
    "198": {
        "QA": {
            "exact_match": 89.39176821925726,
            "f1": 95.26671374081278
        },
        "PR": {
            "p@1": 0.9909325177014595,
            "p@2": 0.9994280140648331,
            "p@3": 1.0
        },
        "PRQA": {
            "exact_match": 88.91611675738163,
            "f1": 94.84111558779368
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 633417 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 633417 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
