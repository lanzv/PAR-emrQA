2024-05-06 10:33:23 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 134 ---------------
2024-05-06 10:33:23 INFO     Contexts were splited into 19795 sentence groups, which are 66.4261744966443 groups on average per one report
2024-05-06 10:33:23 INFO     Contexts were splited into 1585 paragraphs, which are 5.318791946308725 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 1064.9192429022082
2024-05-06 10:33:24 INFO     Contexts were splited into 2264 sentence groups, which are 53.904761904761905 groups on average per one report
2024-05-06 10:33:24 INFO     Contexts were splited into 204 paragraphs, which are 4.857142857142857 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 900.3333333333334
2024-05-06 10:33:24 INFO     Contexts were splited into 4992 sentence groups, which are 58.04651162790697 groups on average per one report
2024-05-06 10:33:24 INFO     Contexts were splited into 428 paragraphs, which are 4.976744186046512 paragraphs on average per one report. There are 9 unique topics with frequency threshold (greater or equal) 134. The overall paragraph average length (characters) is 1005.4649532710281
2024-05-06 10:34:02 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-06 10:42:05 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-06 12:46:00 INFO     the model is trained
2024-05-06 13:11:24 INFO     evaluation data are prepared
2024-05-06 18:36:07 INFO     QA scores: {'exact_match': 90.89940272626559, 'f1': 96.53107347092441}
2024-05-06 18:36:08 INFO     PR scores: {'p@1': 0.9944065796445258, 'p@2': 0.999837435576321, 'p@3': 0.9999638745725158}
2024-05-06 18:36:17 INFO     PRQA scores: {'exact_match': 90.38401329415731, 'f1': 96.12891950835483}
{'loss': 0.6723, 'grad_norm': 1.4847880601882935, 'learning_rate': 2.9077831058649946e-05, 'epoch': 0.03073896471166851}
{'loss': 0.2135, 'grad_norm': 36.12949752807617, 'learning_rate': 2.815566211729989e-05, 'epoch': 0.06147792942333702}
{'loss': 0.1737, 'grad_norm': 4.173389434814453, 'learning_rate': 2.7233493175949835e-05, 'epoch': 0.09221689413500553}
{'loss': 0.1592, 'grad_norm': 4.357237815856934, 'learning_rate': 2.631132423459978e-05, 'epoch': 0.12295585884667404}
{'loss': 0.1365, 'grad_norm': 0.173256978392601, 'learning_rate': 2.5389155293249726e-05, 'epoch': 0.15369482355834255}
{'loss': 0.1457, 'grad_norm': 3.153850555419922, 'learning_rate': 2.4466986351899668e-05, 'epoch': 0.18443378827001106}
{'loss': 0.1259, 'grad_norm': 0.03125939145684242, 'learning_rate': 2.3544817410549614e-05, 'epoch': 0.21517275298167957}
{'loss': 0.1119, 'grad_norm': 7.151059627532959, 'learning_rate': 2.262264846919956e-05, 'epoch': 0.24591171769334808}
{'loss': 0.1155, 'grad_norm': 11.601214408874512, 'learning_rate': 2.1700479527849505e-05, 'epoch': 0.2766506824050166}
{'loss': 0.1015, 'grad_norm': 8.353452682495117, 'learning_rate': 2.0778310586499448e-05, 'epoch': 0.3073896471166851}
{'loss': 0.1023, 'grad_norm': 1.1072570085525513, 'learning_rate': 1.985614164514939e-05, 'epoch': 0.33812861182835363}
{'loss': 0.0993, 'grad_norm': 14.448917388916016, 'learning_rate': 1.8933972703799336e-05, 'epoch': 0.3688675765400221}
{'loss': 0.099, 'grad_norm': 0.1350613683462143, 'learning_rate': 1.801180376244928e-05, 'epoch': 0.39960654125169065}
{'loss': 0.0764, 'grad_norm': 12.065377235412598, 'learning_rate': 1.7089634821099224e-05, 'epoch': 0.43034550596335913}
{'loss': 0.087, 'grad_norm': 2.717780113220215, 'learning_rate': 1.616746587974917e-05, 'epoch': 0.46108447067502767}
{'loss': 0.0873, 'grad_norm': 13.361827850341797, 'learning_rate': 1.5245296938399115e-05, 'epoch': 0.49182343538669615}
{'loss': 0.0791, 'grad_norm': 12.03177547454834, 'learning_rate': 1.432312799704906e-05, 'epoch': 0.5225624000983646}
{'loss': 0.0727, 'grad_norm': 0.05179133266210556, 'learning_rate': 1.3400959055699003e-05, 'epoch': 0.5533013648100332}
{'loss': 0.0738, 'grad_norm': 0.022729143500328064, 'learning_rate': 1.2478790114348949e-05, 'epoch': 0.5840403295217017}
{'loss': 0.0722, 'grad_norm': 0.020965319126844406, 'learning_rate': 1.1556621172998893e-05, 'epoch': 0.6147792942333702}
{'loss': 0.0625, 'grad_norm': 0.05501561239361763, 'learning_rate': 1.0634452231648839e-05, 'epoch': 0.6455182589450388}
{'loss': 0.0642, 'grad_norm': 0.7846471667289734, 'learning_rate': 9.712283290298783e-06, 'epoch': 0.6762572236567073}
{'loss': 0.0619, 'grad_norm': 0.08706732094287872, 'learning_rate': 8.790114348948728e-06, 'epoch': 0.7069961883683757}
{'loss': 0.0585, 'grad_norm': 0.03944180905818939, 'learning_rate': 7.867945407598672e-06, 'epoch': 0.7377351530800442}
{'loss': 0.0558, 'grad_norm': 8.409265518188477, 'learning_rate': 6.945776466248617e-06, 'epoch': 0.7684741177917128}
{'loss': 0.0451, 'grad_norm': 0.0388064831495285, 'learning_rate': 6.023607524898562e-06, 'epoch': 0.7992130825033813}
{'loss': 0.0533, 'grad_norm': 15.875504493713379, 'learning_rate': 5.101438583548506e-06, 'epoch': 0.8299520472150498}
{'loss': 0.0463, 'grad_norm': 10.597427368164062, 'learning_rate': 4.17926964219845e-06, 'epoch': 0.8606910119267183}
{'loss': 0.0516, 'grad_norm': 1.778120756149292, 'learning_rate': 3.2571007008483955e-06, 'epoch': 0.8914299766383869}
{'loss': 0.0463, 'grad_norm': 25.76280975341797, 'learning_rate': 2.3349317594983404e-06, 'epoch': 0.9221689413500553}
{'loss': 0.0384, 'grad_norm': 0.010791388340294361, 'learning_rate': 1.4127628181482848e-06, 'epoch': 0.9529079060617238}
{'loss': 0.0403, 'grad_norm': 0.21640318632125854, 'learning_rate': 4.905938767982294e-07, 'epoch': 0.9836468707733923}
{'eval_loss': 0.2580888271331787, 'eval_runtime': 3116.631, 'eval_samples_per_second': 183.264, 'eval_steps_per_second': 0.716, 'epoch': 1.0}
{'train_runtime': 7434.6969, 'train_samples_per_second': 35.004, 'train_steps_per_second': 2.188, 'train_loss': 0.10613175903052022, 'epoch': 1.0}
Post-processing 897369 example predictions split into 1972030 features.
{
    "134": {
        "QA": {
            "exact_match": 90.89940272626559,
            "f1": 96.53107347092441
        },
        "PR": {
            "p@1": 0.9944065796445258,
            "p@2": 0.999837435576321,
            "p@3": 0.9999638745725158
        },
        "PRQA": {
            "exact_match": 90.38401329415731,
            "f1": 96.12891950835483
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 2729431 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 2729431 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
