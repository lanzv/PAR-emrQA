2024-05-07 05:13:02 INFO     ------------- Experiment: model ClinicalBERT, frequency threshold 154 ---------------
2024-05-07 05:13:02 INFO     Contexts were splited into 716 paragraphs, which are 2.402684563758389 paragraphs on average per one report. The overall paragraph average length (characters) is 2310.9930167597763
2024-05-07 05:13:02 INFO     Contexts were splited into 79 paragraphs, which are 1.880952380952381 paragraphs on average per one report. The overall paragraph average length (characters) is 2278.4430379746836
2024-05-07 05:13:03 INFO     Contexts were splited into 188 paragraphs, which are 2.186046511627907 paragraphs on average per one report. The overall paragraph average length (characters) is 2243.494680851064
2024-05-07 05:13:30 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/Bio_ClinicalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 05:19:49 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 06:48:44 INFO     the model is trained
2024-05-07 07:10:03 INFO     evaluation data are prepared
2024-05-07 11:07:55 INFO     QA scores: {'exact_match': 91.87478926833967, 'f1': 97.20881033424071}
2024-05-07 11:07:56 INFO     PR scores: {'p@1': 0.9899691729685468, 'p@2': 0.9984285439044362, 'p@3': 0.9997651847213526}
2024-05-07 11:08:06 INFO     PRQA scores: {'exact_match': 91.0722026877318, 'f1': 96.50703999402299}
{'loss': 0.6661, 'grad_norm': 9.482003211975098, 'learning_rate': 2.866417312316324e-05, 'epoch': 0.0445275625612254}
{'loss': 0.2495, 'grad_norm': 10.111000061035156, 'learning_rate': 2.7328346246326474e-05, 'epoch': 0.0890551251224508}
{'loss': 0.2042, 'grad_norm': 1.5411642789840698, 'learning_rate': 2.5992519369489715e-05, 'epoch': 0.1335826876836762}
{'loss': 0.1727, 'grad_norm': 1.117608904838562, 'learning_rate': 2.4656692492652955e-05, 'epoch': 0.1781102502449016}
{'loss': 0.1484, 'grad_norm': 0.27602821588516235, 'learning_rate': 2.332086561581619e-05, 'epoch': 0.222637812806127}
{'loss': 0.1415, 'grad_norm': 8.983012199401855, 'learning_rate': 2.198503873897943e-05, 'epoch': 0.2671653753673524}
{'loss': 0.1401, 'grad_norm': 9.185224533081055, 'learning_rate': 2.064921186214267e-05, 'epoch': 0.3116929379285778}
{'loss': 0.1243, 'grad_norm': 0.6178903579711914, 'learning_rate': 1.9313384985305906e-05, 'epoch': 0.3562205004898032}
{'loss': 0.1063, 'grad_norm': 2.019960880279541, 'learning_rate': 1.7977558108469142e-05, 'epoch': 0.4007480630510286}
{'loss': 0.0933, 'grad_norm': 13.363991737365723, 'learning_rate': 1.6641731231632383e-05, 'epoch': 0.445275625612254}
{'loss': 0.1021, 'grad_norm': 3.0944700241088867, 'learning_rate': 1.530590435479562e-05, 'epoch': 0.4898031881734794}
{'loss': 0.0962, 'grad_norm': 9.881231307983398, 'learning_rate': 1.3970077477958858e-05, 'epoch': 0.5343307507347048}
{'loss': 0.0889, 'grad_norm': 1.4394183158874512, 'learning_rate': 1.2634250601122095e-05, 'epoch': 0.5788583132959302}
{'loss': 0.0832, 'grad_norm': 0.027617352083325386, 'learning_rate': 1.1298423724285332e-05, 'epoch': 0.6233858758571555}
{'loss': 0.0712, 'grad_norm': 0.2283502221107483, 'learning_rate': 9.962596847448572e-06, 'epoch': 0.667913438418381}
{'loss': 0.076, 'grad_norm': 10.908319473266602, 'learning_rate': 8.626769970611809e-06, 'epoch': 0.7124410009796064}
{'loss': 0.0639, 'grad_norm': 0.11261097341775894, 'learning_rate': 7.2909430937750465e-06, 'epoch': 0.7569685635408318}
{'loss': 0.0712, 'grad_norm': 28.215091705322266, 'learning_rate': 5.955116216938285e-06, 'epoch': 0.8014961261020572}
{'loss': 0.0579, 'grad_norm': 0.04050524905323982, 'learning_rate': 4.6192893401015235e-06, 'epoch': 0.8460236886632826}
{'loss': 0.0614, 'grad_norm': 0.003961053676903248, 'learning_rate': 3.283462463264761e-06, 'epoch': 0.890551251224508}
{'loss': 0.0494, 'grad_norm': 0.1982654482126236, 'learning_rate': 1.9476355864279993e-06, 'epoch': 0.9350788137857333}
{'loss': 0.0596, 'grad_norm': 1.857283592224121, 'learning_rate': 6.11808709591237e-07, 'epoch': 0.9796063763469588}
{'eval_loss': 0.3008154034614563, 'eval_runtime': 2303.8537, 'eval_samples_per_second': 178.748, 'eval_steps_per_second': 0.698, 'epoch': 1.0}
{'train_runtime': 5334.2106, 'train_samples_per_second': 33.68, 'train_steps_per_second': 2.105, 'train_loss': 0.1314006897653452, 'epoch': 1.0}
Post-processing 524311 example predictions split into 1379527 features.
{
    "154": {
        "QA": {
            "exact_match": 91.87478926833967,
            "f1": 97.20881033424071
        },
        "PR": {
            "p@1": 0.9899691729685468,
            "p@2": 0.9984285439044362,
            "p@3": 0.9997651847213526
        },
        "PRQA": {
            "exact_match": 91.0722026877318,
            "f1": 96.50703999402299
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 478622 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 478622 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
