2024-05-07 12:55:34 INFO     ------------- Experiment: model BERTbase, frequency threshold 121 ---------------
2024-05-07 12:55:35 INFO     Contexts were splited into 4977 sentence groups, which are 27.19672131147541 groups on average per one report
2024-05-07 12:55:35 INFO     Contexts were splited into 552 paragraphs, which are 3.0163934426229506 paragraphs on average per one report. There are 2 unique topics with frequency threshold (greater or equal) 121. The overall paragraph average length (characters) is 2212.0072463768115
2024-05-07 12:55:36 INFO     Contexts were splited into 818 sentence groups, which are 31.46153846153846 groups on average per one report
2024-05-07 12:55:36 INFO     Contexts were splited into 44 paragraphs, which are 1.6923076923076923 paragraphs on average per one report. There are 2 unique topics with frequency threshold (greater or equal) 121. The overall paragraph average length (characters) is 4164.931818181818
2024-05-07 12:55:36 INFO     Contexts were splited into 1362 sentence groups, which are 25.69811320754717 groups on average per one report
2024-05-07 12:55:37 WARNING  The evidenc 'CEFPODOXIME PROXETIL 200 MG PO BID X 16 doses
Food/Drug Interaction Instruction Give with meals
' is in wrong format and it does not occure in the paragraph 'POTENTIALLY SERIOUS INTERACTION: WARFARIN &amp; SIMVASTATIN
Reason for override: already tolerated , home medication ,
aware
CEFPODOXIME PROXETIL 200 MG PO BID X 16 doses
Starting Today ( 6/25 ) HOLD IF: rash
Food/Drug Interaction Instruction Give with meals
Alert overridden: Override added on 11/4/05 by :
on order for CEFPODOXIME PROXETIL PO ( ref # 703442345 )
Pt. has a POSSIBLE allergy to Penicillins; reaction is
RASH. Reason for override: cannot tolerate floroquinolones
and needs gram neg coverage. has
tolerated cefalosporins well in the past.
'
2024-05-07 12:55:37 INFO     Contexts were splited into 148 paragraphs, which are 2.792452830188679 paragraphs on average per one report. There are 2 unique topics with frequency threshold (greater or equal) 121. The overall paragraph average length (characters) is 2323.0337837837837
2024-05-07 12:55:46 INFO     datasets are converted to Datset format
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ../models/bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-05-07 13:00:04 INFO     training data are prepared
/home/lanz/.local/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-05-07 14:30:42 INFO     the model is trained
2024-05-07 14:36:29 INFO     evaluation data are prepared
2024-05-07 15:55:07 INFO     QA scores: {'exact_match': 29.358704523001588, 'f1': 68.13702735842132}
2024-05-07 15:55:07 INFO     PR scores: {'p@1': 0.9757742365018685, 'p@2': 0.9949959194192689, 'p@3': 0.9985395816330913}
2024-05-07 15:55:10 INFO     PRQA scores: {'exact_match': 28.353593058717408, 'f1': 67.05676088177039}
{'loss': 1.1476, 'grad_norm': 7.48915433883667, 'learning_rate': 2.9065595215847507e-05, 'epoch': 0.031146826138416496}
{'loss': 0.7985, 'grad_norm': 12.859317779541016, 'learning_rate': 2.813119043169501e-05, 'epoch': 0.06229365227683299}
{'loss': 0.7161, 'grad_norm': 14.01131534576416, 'learning_rate': 2.7196785647542515e-05, 'epoch': 0.09344047841524948}
{'loss': 0.6584, 'grad_norm': 8.745221138000488, 'learning_rate': 2.626238086339002e-05, 'epoch': 0.12458730455366598}
{'loss': 0.5928, 'grad_norm': 11.812773704528809, 'learning_rate': 2.5327976079237526e-05, 'epoch': 0.15573413069208247}
{'loss': 0.5338, 'grad_norm': 22.509260177612305, 'learning_rate': 2.4393571295085032e-05, 'epoch': 0.18688095683049896}
{'loss': 0.5067, 'grad_norm': 15.757050514221191, 'learning_rate': 2.3459166510932538e-05, 'epoch': 0.21802778296891548}
{'loss': 0.5105, 'grad_norm': 3.8805277347564697, 'learning_rate': 2.2524761726780044e-05, 'epoch': 0.24917460910733197}
{'loss': 0.4518, 'grad_norm': 12.790166854858398, 'learning_rate': 2.1590356942627546e-05, 'epoch': 0.2803214352457485}
{'loss': 0.4193, 'grad_norm': 17.633216857910156, 'learning_rate': 2.0655952158475052e-05, 'epoch': 0.31146826138416495}
{'loss': 0.4012, 'grad_norm': 24.196964263916016, 'learning_rate': 1.9721547374322558e-05, 'epoch': 0.34261508752258146}
{'loss': 0.3798, 'grad_norm': 10.474493980407715, 'learning_rate': 1.878714259017006e-05, 'epoch': 0.3737619136609979}
{'loss': 0.3632, 'grad_norm': 8.508707046508789, 'learning_rate': 1.7852737806017566e-05, 'epoch': 0.40490873979941444}
{'loss': 0.3607, 'grad_norm': 1.664538860321045, 'learning_rate': 1.6918333021865072e-05, 'epoch': 0.43605556593783096}
{'loss': 0.3212, 'grad_norm': 25.31967544555664, 'learning_rate': 1.5983928237712578e-05, 'epoch': 0.4672023920762474}
{'loss': 0.291, 'grad_norm': 13.193565368652344, 'learning_rate': 1.5049523453560082e-05, 'epoch': 0.49834921821466394}
{'loss': 0.2931, 'grad_norm': 6.506579875946045, 'learning_rate': 1.4115118669407588e-05, 'epoch': 0.5294960443530804}
{'loss': 0.2769, 'grad_norm': 14.957552909851074, 'learning_rate': 1.3180713885255093e-05, 'epoch': 0.560642870491497}
{'loss': 0.267, 'grad_norm': 24.73577880859375, 'learning_rate': 1.2246309101102598e-05, 'epoch': 0.5917896966299134}
{'loss': 0.2641, 'grad_norm': 24.63225555419922, 'learning_rate': 1.1311904316950103e-05, 'epoch': 0.6229365227683299}
{'loss': 0.2479, 'grad_norm': 12.564117431640625, 'learning_rate': 1.0377499532797607e-05, 'epoch': 0.6540833489067464}
{'loss': 0.246, 'grad_norm': 11.068892478942871, 'learning_rate': 9.443094748645115e-06, 'epoch': 0.6852301750451629}
{'loss': 0.2343, 'grad_norm': 7.592868804931641, 'learning_rate': 8.508689964492619e-06, 'epoch': 0.7163770011835794}
{'loss': 0.1969, 'grad_norm': 11.85561752319336, 'learning_rate': 7.574285180340123e-06, 'epoch': 0.7475238273219958}
{'loss': 0.2106, 'grad_norm': 10.317780494689941, 'learning_rate': 6.639880396187628e-06, 'epoch': 0.7786706534604124}
{'loss': 0.2112, 'grad_norm': 12.791358947753906, 'learning_rate': 5.705475612035134e-06, 'epoch': 0.8098174795988289}
{'loss': 0.1867, 'grad_norm': 8.761954307556152, 'learning_rate': 4.771070827882639e-06, 'epoch': 0.8409643057372453}
{'loss': 0.1915, 'grad_norm': 10.44666576385498, 'learning_rate': 3.836666043730144e-06, 'epoch': 0.8721111318756619}
{'loss': 0.1786, 'grad_norm': 20.814577102661133, 'learning_rate': 2.9022612595776493e-06, 'epoch': 0.9032579580140784}
{'loss': 0.161, 'grad_norm': 23.450960159301758, 'learning_rate': 1.9678564754251542e-06, 'epoch': 0.9344047841524948}
{'loss': 0.1688, 'grad_norm': 0.019107135012745857, 'learning_rate': 1.0334516912726594e-06, 'epoch': 0.9655516102909114}
{'loss': 0.1578, 'grad_norm': 0.8526057600975037, 'learning_rate': 9.904690712016446e-08, 'epoch': 0.9966984364293279}
{'eval_loss': 0.8275555968284607, 'eval_runtime': 1086.9836, 'eval_samples_per_second': 178.815, 'eval_steps_per_second': 0.699, 'epoch': 1.0}
{'train_runtime': 5437.043, 'train_samples_per_second': 47.238, 'train_steps_per_second': 2.953, 'train_loss': 0.37259791070097725, 'epoch': 1.0}
Post-processing 138930 example predictions split into 471816 features.
{
    "121": {
        "QA": {
            "exact_match": 29.358704523001588,
            "f1": 68.13702735842132
        },
        "PR": {
            "p@1": 0.9757742365018685,
            "p@2": 0.9949959194192689,
            "p@3": 0.9985395816330913
        },
        "PRQA": {
            "exact_match": 28.353593058717408,
            "f1": 67.05676088177039
        }
    }
}
slurmstepd: error: common_file_write_uint32s: write pid 2655022 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 2655022 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
